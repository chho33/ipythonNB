{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##推薦作法:\n",
    "- 將需要的資料都存成變數：\n",
    "    - 新聞內容：class(python裡class是保留字，所以我在下面的code改成category),title,newsDate,journalist,content,hit,url,source\n",
    "    - 評論：url,commenter,comment\n",
    "- 將這些變數用list或dictionary存起來\n",
    "- 將存的list或dictionary轉成pandas\n",
    "- 直接用DataFrame.to_csv(filename,encoding=\"utf-8\")轉成csv\n",
    "- 下面的code有存進資料庫的部分，如果不存資料庫的人可以把那些註解掉，存成csv就好，如果要存進資料庫，則記得先見好資料庫，資料庫的code詳見news.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一日期或日期區間  ETToday_day(startday,endday,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "# year, month要輸入integer(ex. 2012,3)\n",
    "# 如果抓本月的新聞，會預設抓到今天前一天的新聞\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import traceback\n",
    "import string  \n",
    "\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(%s,%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,commenter,commenterUrl,comment,url])\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,url,newsRaw):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into newsRaw(url,newsRaw)values(%s,%s)\",[url,newsRaw])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "\n",
    "sentinel = object()\n",
    "def ETToday_day(startday=(str(date.today()-timedelta(1))),endday=sentinel,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0):\n",
    "     \n",
    "    if endday is sentinel:\n",
    "        endday=startday\n",
    "    \n",
    "    def convert_day(d):\n",
    "        return datetime.strptime(d, '%Y-%m-%d')\n",
    "    \n",
    "    ed=convert_day(endday)\n",
    "    sd=convert_day(startday)\n",
    "\n",
    "    assert ed >= sd, \"endday must after startday\"\n",
    "    \n",
    "    ds = []\n",
    "    for i in xrange(0,(ed-sd).days+1):\n",
    "        ds.append(str((ed- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "\n",
    "    url_all =[]\n",
    "    for newsDate in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%newsDate,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%newsDate,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%newsDate,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%newsDate,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%newsDate,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%newsDate,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%newsDate,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%newsDate\n",
    "                   }\n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            try:\n",
    "                url_categories[str(cat)]=url_dic[str(cat)]\n",
    "                url_all.append(url_categories[str(cat)])\n",
    "            except:\n",
    "                print newsDate, cat, url_dic[str(cat)], \"\\n\"\n",
    "                print traceback.format_exc() + \"\\n\"\n",
    "    \n",
    "    identify = string.maketrans('', '')\n",
    "    delEStr = string.punctuation\n",
    "    L = []\n",
    "    for cat in url_all:\n",
    "        try:\n",
    "            res = requests.get(cat)\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            soups = [soup]\n",
    "        except:\n",
    "            print cat\n",
    "            raise \n",
    "        if pageCount >1:\n",
    "            for i in xrange(2,pageCount+1):\n",
    "                curl = str(cat).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                res = requests.get(curl)\n",
    "                res.encoding=\"utf-8\"\n",
    "                soups.append(BeautifulSoup(res.text))\n",
    "\n",
    "        for soup in soups:         \n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                try:\n",
    "                    timeRegex=re.search(\"\\[(\\d\\d)\\/(\\d\\d) (\\d{1,2}\\:\\d{1,2})\\]\",block.select('span')[0].text)\n",
    "                    testDate=timeRegex.group(1)+'-'+timeRegex.group(2)\n",
    "                    if not testDate == re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'):\n",
    "                        continue\n",
    "                    newsTime=timeRegex.group(3)\n",
    "                    title=block.select('a')[0].text\n",
    "                    aLink=block.select('a')[0]['href']\n",
    "                except:\n",
    "                    print cat\n",
    "                    raise\n",
    "                #########get page breakpoint\n",
    "                #driver = webdriver.Firefox()\n",
    "                #driver = webdriver.Chrome()\n",
    "                driver = webdriver.PhantomJS()\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept-Encoding'] = 'gzip, deflate, sdch'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Cache-Control'] = 'max-age=0'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Connection'] = 'keep-alive'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.User-Agent'] = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "                try:\n",
    "                    driver.get(aLink)\n",
    "                    WebDriverWait(driver, 30).until(\n",
    "                            EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "                        )\n",
    "                    html = driver.page_source\n",
    "                    cont = str(html.encode('utf-8'))\n",
    "                    soupCont = BeautifulSoup(cont)\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback: \\n\", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                    continue\n",
    "                finally:\n",
    "                    driver.quit()\n",
    "                #########get page breakpoint\n",
    "\n",
    "                #########content breakpoint\n",
    "                try:\n",
    "                    content=\"\"\n",
    "                    contentRaw = soupCont.select('.story > sectione > p')\n",
    "                    try:\n",
    "                        for i in xrange(0,len(contentRaw)):\n",
    "                            for con in contentRaw[i].select('img'):\n",
    "                                contentRaw[i].img.decompose()\n",
    "                    except:\n",
    "                        pass\n",
    "                    for p in contentRaw:\n",
    "                        content = content + p.text\n",
    "                    content=content.strip()\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback: \\n\", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########content breakpoint\n",
    "\n",
    "                #########journist breakpoint\n",
    "                jor = str(BeautifulSoup(cont).select('.story')[0].prettify().encode(\"utf-8\"))\n",
    "                try:\n",
    "                    journalist=re.search('([^圖].*?)／.*?報導.*?', jor).group(1).strip()\n",
    "                    journalist=journalist.translate(identify, delEStr)\n",
    "                    if '記者' in journalist:\n",
    "                        journalist=re.sub('記者','',journalist)\n",
    "                    journalist=re.sub('、', '', journalist)\n",
    "                except:\n",
    "                    try:\n",
    "                        journalist=re.search('文／(.*?)<',cont).group(1).strip()\n",
    "                        journalist=journalist.translate(identify, delEStr)\n",
    "                        journalist=re.sub('、', '', journalist)\n",
    "                    except Exception as e:\n",
    "                        try:\n",
    "                            journalist=None\n",
    "                            f=open(\"ETTodayException.log\",\"a\")\n",
    "                            ExList=[\n",
    "                                \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                                \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                                \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                                \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                                \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                                \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                                \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                                \"\\t -Exception Traceback: \\n \", \n",
    "                                str(traceback.format_exc().decode('utf-8').encode('utf-8')) + \"\\n\"\n",
    "                            ]\n",
    "                            f.writelines(ExList)\n",
    "                            f.close\n",
    "                        except:\n",
    "                            print \"jor: \",aLink,\" WTF\"\n",
    "                #########journist breakpoint\n",
    "\n",
    "                #########category breakpoint\n",
    "                category=block.select('em')[0].text\n",
    "                '''\n",
    "                if not category == cat.decode(\"utf-8\"):\n",
    "                    try:\n",
    "                        raise Exception\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \\n\", \n",
    "                            str(traceback.format_exc()) + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                '''\n",
    "                #########category breakpoint\n",
    "\n",
    "                try:\n",
    "                    L.append({'class':category,'title':title,'newsDate':newsDate,'newsTime':newsTime,'journalist':journalist,'content':content,'hit':hit,'url':aLink,'source':'ETToday'})\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                #########comment breakpoint\n",
    "                comments=[]\n",
    "                try:\n",
    "                    commLink0 = soupCont.find(\"div\",re.compile('fb-comments.*'))\n",
    "                    commLink1= commLink0.select(' span > iframe')[0]['src']\n",
    "                    commLink=re.sub(r\"numposts=\\d{1,3}&\", \"numposts=100&\", commLink1)\n",
    "                    resComm = requests.get(commLink)\n",
    "                    resComm.encoding = \"utf-8\"\n",
    "                    soupComm = BeautifulSoup(resComm.text)      \n",
    "                    commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "                    for comm in commentBlock: \n",
    "                        dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "                        commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "                        commentTime=dt.group(4)\n",
    "                        commenter=comm.select('.profileName')[0].text\n",
    "                        commenterUrl=comm.select('.profileName')[0]['href']\n",
    "                        comment=comm.select('.postText')[0].text\n",
    "                        comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: comment\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback: \\n\", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########comment breakpoint\n",
    "\n",
    "                #################連資料庫用\n",
    "                hit = None\n",
    "                #print category,title,newsDate,newsTime,journalist,content,hit,aLink,commentDate,commentTime,commenter,comment\n",
    "                try:\n",
    "                    conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                    insert_news(conn,category,title,newsDate,newsTime,journalist,content,hit,aLink)\n",
    "                    insert_newsRaw(conn,aLink,res.text)\n",
    "                    for c in comments:\n",
    "                        insert_comments(conn,c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5])\n",
    "                except:\n",
    "                    print \"something not write in DB \\n\", traceback.format_exc(),aLink,\"\\n\"\n",
    "                finally:\n",
    "                    close(conn)\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "\n",
    "    \n",
    "    #########write_in_csv breakpoint\n",
    "    try:\n",
    "        # pandas - content\n",
    "        df = pd.DataFrame(L,columns =['class','title','newsDate','newsTime','journalist','content','hit','url','source'])\n",
    "        # pandas - comment\n",
    "        df_comm = pd.DataFrame(comments,columns =['commentDate','commentTime','commenter','commenterUrl','comment','url','remark'])\n",
    "        \n",
    "        # write csv\n",
    "        if startday==endday:\n",
    "            std=\"\".join(startday.split('-'))\n",
    "            filename_content=\"ETTdoay_content_\"+std+\".csv\"\n",
    "            filename_comment=\"ETTdoay_comment_\"+std+\".csv\"\n",
    "        else:\n",
    "            std=\"\".join(startday.split('-'))\n",
    "            end=\"\".join(endday.split('-'))\n",
    "            filename_content=\"ETTdoay_content_\"+\"_\"+std+\"-\"+end+\".csv\"\n",
    "            filename_comment=\"ETTdoay_comment_\"+\"_\"+std+\"-\"+end+\".csv\"\n",
    "        ## write content in csv\n",
    "        f=open(filename_content,\"w\")\n",
    "        df.to_csv(filename_content,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        ## write comment in csv\n",
    "        f=open(filename_comment,\"w\")\n",
    "        df_comm.to_csv(filename_comment,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        f=open(\"ETTodayException.log\",\"a\")\n",
    "        ExList=[\n",
    "            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "            \"\\t -BreakPoint: write_in_csv\" + \"\\n\",\n",
    "            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "            \"\\t -Exception Traceback: \\n\", \n",
    "            str(traceback.format_exc()) + \"\\n\"\n",
    "        ]\n",
    "        f.writelines(ExList)\n",
    "        f.close\n",
    "#########write_in_csv breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jor:  http://www.ettoday.net/news/20150502/499637.htm  WTF\n",
      "jor:  http://www.ettoday.net/news/20150502/499555.htm  WTF\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-5305284d9bf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mETToday_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2015-05-02'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"政治\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"財經\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"國際\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"大陸\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-268-8e56f97bcaca>\u001b[0m in \u001b[0;36mETToday_day\u001b[0;34m(startday, endday, category, sleep_time)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpageCount\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mcurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".htm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".htm\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0msoups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;31m# By explicitly closing the session, we avoid leaving sockets open which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# can trigger a ResourceWarning in some cases, and look like a memory leak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    463\u001b[0m         }\n\u001b[1;32m    464\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    368\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                 )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[1;32m    542\u001b[0m             httplib_response = self._make_request(conn, method, url,\n\u001b[1;32m    543\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                                                   body=body, headers=headers)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;31m# conn.request() calls httplib.*.request, not the method in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;31m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_content_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body)\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmessage_body\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0mmessage_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0;31m#message_body was not a string (i.e. it is a file) and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/connection.pyc\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/connection.pyc\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 134\u001b[0;31m                 (self.host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/util/connection.pyc\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run\n",
    "a = time.clock()\n",
    "ETToday_day('2015-05-02',category=[\"政治\",\"財經\",\"國際\",\"大陸\"])\n",
    "time.clock() - a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一或多月份  ETToday_month(year,month,year2,month2,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "# year, month要輸入integer(ex. 2012,3)\n",
    "# 如果抓本月的新聞，會預設抓到今天前一天的新聞\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(%s,%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,commenter,commenterUrl,comment,url])\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,url,newsRaw):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into newsRaw(url,newsRaw)values(%s,%s)\",[url,newsRaw])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "\n",
    "sentinel = object()\n",
    "def ETToday_month(year,month,year2=sentinel,month2=sentinel,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0):\n",
    "    \n",
    "    if year2 is sentinel:\n",
    "        year2 = year\n",
    "    if month2 is sentinel:\n",
    "        month2 = month\n",
    "    \n",
    "    assert date(year2,month2,1) >= date(year,month,1), \"year2,month2 must after year,month\"\n",
    "\n",
    "    def first_day_of_month_d(d):\n",
    "        return date(d.year, d.month, 1)\n",
    "\n",
    "    def first_day_of_month(y,m):\n",
    "        return date(y,m,1)\n",
    "\n",
    "    def last_day_of_month(y,m):\n",
    "        return date(y,m+1,1) - timedelta(days = 1)\n",
    "\n",
    "    def diff_months_d(d1, d2):\n",
    "        return (d1.year - d2.year)*12 + d1.month - d2.month\n",
    "\n",
    "    def diff_days(y,m,y2,m2):\n",
    "        return abs(last_day_of_month(y2,m2)-first_day_of_month(y,m)).days\n",
    "\n",
    "    # check if input month exceed current month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year,month))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year2,month2))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month2\n",
    "\n",
    "    if diff_months_d(date.today(),first_day_of_month(year2,month2))==0:\n",
    "        duration=(date.today()-first_day_of_month_d(date.today())).days\n",
    "        ds = []\n",
    "        for i in xrange(1,duration+1):\n",
    "            ds.append(str((date.today()- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "    else:\n",
    "        #duration=calendar.monthrange(year,month)[1]\n",
    "        duration=diff_days(year,month,year2,month2)\n",
    "        ds = []\n",
    "        for i in xrange(0,duration+1):\n",
    "            ds.append(str((last_day_of_month(year2,month2)- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "    \n",
    "    url_all =[]\n",
    "    for newsDate in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%newsDate,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%newsDate,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%newsDate,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%newsDate,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%newsDate,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%newsDate,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%newsDate,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%newsDate\n",
    "                   }\n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            try:\n",
    "                url_categories[str(cat)]=url_dic[str(cat)]\n",
    "                url_all.append(url_categories[str(cat)])\n",
    "            except:\n",
    "                print newsDate, cat, url_dic[str(cat)], \"\\n\"\n",
    "                print traceback.format_exc() + \"\\n\"\n",
    "\n",
    "    identify = string.maketrans('', '')\n",
    "    delEStr = string.punctuation\n",
    "    L = []\n",
    "    for cat in url_all:\n",
    "        try:\n",
    "            res = requests.get(cat)\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            soups = [soup]\n",
    "        except:\n",
    "            print cat\n",
    "            raise \n",
    "        if pageCount >1:\n",
    "            for i in xrange(2,pageCount+1):\n",
    "                curl = str(cat).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                res = requests.get(curl)\n",
    "                res.encoding=\"utf-8\"\n",
    "                soups.append(BeautifulSoup(res.text))\n",
    "\n",
    "        for soup in soups:         \n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                try:\n",
    "                    timeRegex=re.search(\"\\[(\\d\\d)\\/(\\d\\d) (\\d{1,2}\\:\\d{1,2})\\]\",block.select('span')[0].text)\n",
    "                    testDate=timeRegex.group(1)+'-'+timeRegex.group(2)\n",
    "                    if not testDate == re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'):\n",
    "                        continue\n",
    "                    newsTime=timeRegex.group(3)\n",
    "                    title=block.select('a')[0].text\n",
    "                    aLink=block.select('a')[0]['href']\n",
    "                except:\n",
    "                    print cat\n",
    "                    raise\n",
    "                #########get page breakpoint\n",
    "                #driver = webdriver.Firefox()\n",
    "                #driver = webdriver.Chrome()\n",
    "                driver = webdriver.PhantomJS()\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept-Encoding'] = 'gzip, deflate, sdch'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Cache-Control'] = 'max-age=0'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Connection'] = 'keep-alive'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.User-Agent'] = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "                try:\n",
    "                    driver.get(aLink)\n",
    "                    WebDriverWait(driver, 30).until(\n",
    "                            EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "                        )\n",
    "                    html = driver.page_source\n",
    "                    cont = str(html.encode('utf-8'))\n",
    "                    soupCont = BeautifulSoup(cont)\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback:\", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                    continue\n",
    "                finally:\n",
    "                    driver.quit()\n",
    "                #########get page breakpoint\n",
    "\n",
    "                #########content breakpoint\n",
    "                try:\n",
    "                    content=\"\"\n",
    "                    contentRaw = soupCont.select('.story > sectione > p')\n",
    "                    try:\n",
    "                        for i in xrange(0,len(contentRaw)):\n",
    "                            for con in contentRaw[i].select('img'):\n",
    "                                contentRaw[i].img.decompose()\n",
    "                    except:\n",
    "                        pass                    \n",
    "                    for p in contentRaw:\n",
    "                        content = content + p.text\n",
    "                    content = content.strip()\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback:\", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########content breakpoint\n",
    "\n",
    "                #########journist breakpoint\n",
    "                jor = str(BeautifulSoup(cont).select('.story')[0].prettify().encode(\"utf-8\"))\n",
    "                try:\n",
    "                    journalist=re.search('([^圖].*?)／.*?報導.*?', jor).group(1).strip()\n",
    "                    journalist=journalist.translate(identify, delEStr)\n",
    "                    if '記者' in journalist:\n",
    "                        journalist=re.sub('記者','',journalist)\n",
    "                    journalist=re.sub('、', '', journalist)\n",
    "                except:\n",
    "                    try:\n",
    "                        journalist=re.search('文／(.*?)<',cont).group(1).strip()\n",
    "                        journalist=journalist.translate(identify, delEStr)\n",
    "                        journalist=re.sub('、', '', journalist)\n",
    "                    except Exception as e:\n",
    "                        journalist=None\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            str(traceback.format_exc().decode('utf-8').encode('utf-8')) + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    except:\n",
    "                        print \"jor: \",aLink,\" WTF\"\n",
    "                #########journist breakpoint\n",
    "\n",
    "                #########category breakpoint\n",
    "                category=block.select('em')[0].text\n",
    "                '''\n",
    "                if not category == cat.decode(\"utf-8\"):\n",
    "                    try:\n",
    "                        raise Exception\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            str(traceback.format_exc()) + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                '''\n",
    "                #########category breakpoint\n",
    "\n",
    "                try:\n",
    "                    L.append({'class':category,'title':title,'newsDate':newsDate,'newsTime':newsTime,'journalist':journalist,'content':content,'hit':hit,'url':aLink,'source':'ETToday'})\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                #########comment breakpoint\n",
    "                comments=[]\n",
    "                try:\n",
    "                    commLink0 = soupCont.find(\"div\",re.compile('fb-comments.*'))\n",
    "                    commLink1= commLink0.select(' span > iframe')[0]['src']\n",
    "                    commLink=re.sub(r\"numposts=\\d{1,3}&\", \"numposts=100&\", commLink1)\n",
    "                    resComm = requests.get(commLink)\n",
    "                    resComm.encoding = \"utf-8\"\n",
    "                    soupComm = BeautifulSoup(resComm.text)      \n",
    "                    commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "                    for comm in commentBlock: \n",
    "                        dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "                        commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "                        commentTime=dt.group(4)\n",
    "                        commenter=comm.select('.profileName')[0].text\n",
    "                        commenterUrl=comm.select('.profileName')[0]['href']\n",
    "                        comment=comm.select('.postText')[0].text\n",
    "                        comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: comment\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback: \", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########comment breakpoint\n",
    "\n",
    "                #################連資料庫用\n",
    "                hit = None\n",
    "                #print category,title,newsDate,newsTime,journalist,content,hit,aLink,commentDate,commentTime,commenter,comment\n",
    "                try:\n",
    "                    conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                    insert_news(conn,category,title,newsDate,newsTime,journalist,content,hit,aLink)\n",
    "                    insert_newsRaw(conn,aLink,res.text)\n",
    "                    for c in comments:\n",
    "                        insert_comments(conn,c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5])\n",
    "                except:\n",
    "                    print \"something not write in DB \\n\", traceback.format_exc(),aLink,\"\\n\"\n",
    "                finally:\n",
    "                    close(conn)\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "    \n",
    "    \n",
    "    #########write_in_csv breakpoint\n",
    "    try:\n",
    "        # pandas - content\n",
    "        df = pd.DataFrame(L,columns =['class','title','newsDate','newsTime','journalist','content','hit','url','source'])\n",
    "        # pandas - comment\n",
    "        df_comm = pd.DataFrame(comments,columns =['commentDate','commentTime','commenter','commenterUrl','comment','url','remark'])\n",
    "        \n",
    "        # write csv\n",
    "        if (str(year)+str(month))==(str(year2)+str(month2)):\n",
    "            filename_content=\"ETTdoay_content_%d%02d.csv\"%(year,month)\n",
    "        else:\n",
    "            filename_comment=\"ETTdoay_comment_%d%02d-%d%02d.csv\"%(year,month,year2,month2)\n",
    "        ## write content in csv\n",
    "        f=open(filename_content,\"w\")\n",
    "        df.to_csv(filename_content,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        ## write comment in csv\n",
    "        f=open(filename_comment,\"w\")\n",
    "        df_comm.to_csv(filename_comment,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        f=open(\"ETTodayException.log\",\"a\")\n",
    "        ExList=[\n",
    "            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "            \"\\t -BreakPoint: write_in_csv\" + \"\\n\",\n",
    "            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "            \"\\t -Exception Traceback:\", \n",
    "            str(traceback.format_exc()) + \"\\n\"\n",
    "        ]\n",
    "        f.writelines(ExList)\n",
    "        f.close\n",
    "#########write_in_csv breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run\n",
    "a = time.clock()\n",
    "ETToday_month(2015,5,category=[\"政治\",\"財經\",\"國際\",\"大陸\"])\n",
    "time.clock() - a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##直接輸入從今天算起要抓幾天 ETToday(days,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(%s,%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,commenter,commenterUrl,comment,url])\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,url,newsRaw):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into newsRaw(url,newsRaw)values(%s,%s)\",[url,newsRaw])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "    \n",
    "def ETToday(days=1,sleep_time=0,category=[\"政治\",\"財經\",\"國際\",\"大陸\"]):\n",
    "    \n",
    "    ds = []\n",
    "    for i in xrange(1,days+1):\n",
    "        ds.append(str(date.today()- timedelta(i)))\n",
    "    \n",
    "    url_all =[]\n",
    "    for newsDate in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%newsDate,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%newsDate,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%newsDate,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%newsDate,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%newsDate,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%newsDate,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%newsDate,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%newsDate\n",
    "                   }\n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            try:\n",
    "                url_categories[str(cat)]=url_dic[str(cat)]\n",
    "                url_all.append(url_categories[str(cat)])\n",
    "            except:\n",
    "                print newsDate, cat, url_dic[str(cat)], \"\\n\"\n",
    "                print traceback.format_exc() + \"\\n\"\n",
    "\n",
    "    identify = string.maketrans('', '')\n",
    "    delEStr = string.punctuation\n",
    "    L = []\n",
    "    for cat in url_all:\n",
    "        try:\n",
    "            res = requests.get(cat)\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            soups = [soup]\n",
    "        except:\n",
    "            print cat\n",
    "            raise \n",
    "        if pageCount >1:\n",
    "            for i in xrange(2,pageCount+1):\n",
    "                curl = str(cat).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                res = requests.get(curl)\n",
    "                res.encoding=\"utf-8\"\n",
    "                soups.append(BeautifulSoup(res.text))\n",
    "\n",
    "        for soup in soups:         \n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                try:\n",
    "                    timeRegex=re.search(\"\\[(\\d\\d)\\/(\\d\\d) (\\d{1,2}\\:\\d{1,2})\\]\",block.select('span')[0].text)\n",
    "                    testDate=timeRegex.group(1)+'-'+timeRegex.group(2)\n",
    "                    if not testDate == re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'):\n",
    "                        continue\n",
    "                    newsTime=timeRegex.group(3)\n",
    "                    title=block.select('a')[0].text\n",
    "                    aLink=block.select('a')[0]['href']\n",
    "                except:\n",
    "                    print cat\n",
    "                    raise\n",
    "                #########get page breakpoint\n",
    "                #driver = webdriver.Firefox()\n",
    "                #driver = webdriver.Chrome()\n",
    "                driver = webdriver.PhantomJS()\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept-Encoding'] = 'gzip, deflate, sdch'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Cache-Control'] = 'max-age=0'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Connection'] = 'keep-alive'\n",
    "                webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.User-Agent'] = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "                try:    \n",
    "                    driver.get(aLink)\n",
    "                    WebDriverWait(driver, 30).until(\n",
    "                            EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "                        )\n",
    "                    html = driver.page_source\n",
    "                    cont = str(html.encode('utf-8'))\n",
    "                    soupCont = BeautifulSoup(cont)\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback:\", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                    continue\n",
    "                finally:\n",
    "                    driver.quit()\n",
    "                #########get page breakpoint\n",
    "\n",
    "                #########content breakpoint\n",
    "                try:\n",
    "                    content=\"\"\n",
    "                    contentRaw = soupCont.select('.story > sectione > p')\n",
    "                    try:\n",
    "                        for i in xrange(0,len(contentRaw)):\n",
    "                            for con in contentRaw[i].select('img'):\n",
    "                                contentRaw[i].img.decompose()\n",
    "                    except:\n",
    "                        pass\n",
    "                        for p in contentRaw:\n",
    "                            content = content + p.text\n",
    "                        content = content.strip()\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback:\", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########content breakpoint\n",
    "\n",
    "                #########journist breakpoint\n",
    "                jor = str(BeautifulSoup(cont).select('.story')[0].prettify().encode(\"utf-8\"))\n",
    "                try:\n",
    "                    journalist=re.search('([^圖].*?)／.*?報導.*?',jor).group(1).strip()\n",
    "                    journalist=journalist.translate(identify, delEStr)\n",
    "                    if '記者' in journalist:\n",
    "                        journalist=re.sub('記者','',journalist)\n",
    "                    journalist=re.sub('、', '', journalist)\n",
    "                except:\n",
    "                    try:\n",
    "                        journalist=re.search('文／(.*?)<',cont).group(1).strip()\n",
    "                        journalist=journalist.translate(identify, delEStr)\n",
    "                        journalist=re.sub('、', '', journalist)\n",
    "                    except Exception as e:\n",
    "                        journalist=None\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            str(traceback.format_exc().decode('utf-8').encode('utf-8')) + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    except:\n",
    "                        print \"jor: \",aLink,\" WTF\"\n",
    "                #########journist breakpoint\n",
    "\n",
    "                #########category breakpoint\n",
    "                category=block.select('em')[0].text\n",
    "                '''if not category == cat.decode(\"utf-8\"):\n",
    "                    try:\n",
    "                        raise Exception\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            str(traceback.format_exc()) + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close'''\n",
    "                #########category breakpoint\n",
    "\n",
    "                try:\n",
    "                    L.append({'class':category,'title':title,'newsDate':newsDate,'newsTime':newsTime,'journalist':journalist,'content':content,'hit':hit,'url':aLink,'source':'ETToday'})\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                #########comment breakpoint\n",
    "                comments=[]\n",
    "                try:\n",
    "                    commLink0 = soupCont.find(\"div\",re.compile('fb-comments.*'))\n",
    "                    commLink1= commLink0.select(' span > iframe')[0]['src']\n",
    "                    commLink=re.sub(r\"numposts=\\d{1,3}&\", \"numposts=100&\", commLink1)\n",
    "                    resComm = requests.get(commLink)\n",
    "                    resComm.encoding = \"utf-8\"\n",
    "                    soupComm = BeautifulSoup(resComm.text)      \n",
    "                    commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "                    for comm in commentBlock: \n",
    "                        dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "                        commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "                        commentTime=dt.group(4)\n",
    "                        commenter=comm.select('.profileName')[0].text\n",
    "                        commenterUrl=comm.select('.profileName')[0]['href']\n",
    "                        comment=comm.select('.postText')[0].text\n",
    "                        comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: comment\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                        \"\\t -Exception Traceback: \", \n",
    "                        str(traceback.format_exc()) + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########comment breakpoint\n",
    "\n",
    "                #################連資料庫用\n",
    "                hit = None\n",
    "                #print category,title,newsDate,newsTime,journalist,content,hit,aLink,commentDate,commentTime,commenter,comment\n",
    "                try:\n",
    "                    conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                    insert_news(conn,category,title,newsDate,newsTime,journalist,content,hit,aLink)\n",
    "                    insert_newsRaw(conn,aLink,res.text)\n",
    "                    for c in comments:\n",
    "                        insert_comments(conn,c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5])\n",
    "                except:\n",
    "                    print \"something not write in DB \\n\", traceback.format_exc(),aLink\n",
    "                finally:\n",
    "                    close(conn)\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "    \n",
    "    #########write_in_csv breakpoint\n",
    "    try:\n",
    "        # pandas - content\n",
    "        df = pd.DataFrame(L,columns =['class','title','newsDate','newsTime','journalist','content','hit','url','source'])\n",
    "        # pandas - comment\n",
    "        df_comm = pd.DataFrame(comments,columns =['commentDate','commentTime','commenter','commenterUrl','comment','url','remark'])\n",
    "                               \n",
    "        # write content in csv\n",
    "        f=open(\"ETToday_content.csv\",\"w\")\n",
    "        df.to_csv(\"ETToday_content.csv\",encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        # write comment in csv\n",
    "        f=open(\"ETToday_comment.csv\",\"w\")\n",
    "        df_comm.to_csv(\"ETToday_comment.csv\",encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        f=open(\"ETTodayException.log\",\"a\")\n",
    "        ExList=[\n",
    "            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "            \"\\t -BreakPoint: write_in_csv\" + \"\\n\",\n",
    "            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "            \"\\t -Exception Traceback:\", \n",
    "            str(traceback.format_exc()) + \"\\n\"\n",
    "        ]\n",
    "        f.writelines(ExList)\n",
    "        f.close\n",
    "#########write_in_csv breakpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run\n",
    "a = time.clock()\n",
    "ETToday()\n",
    "time.clock() - a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import traceback\n",
    "import string\n",
    "driver = webdriver.PhantomJS()\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept-Encoding'] = 'gzip, deflate, sdch'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Cache-Control'] = 'max-age=0'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Connection'] = 'keep-alive'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.User-Agent'] = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "aLink=\"http://www.ettoday.net/news/20150620/523337.htm\"\n",
    "try:    \n",
    "    driver.get(aLink)\n",
    "    WebDriverWait(driver, 30).until(\n",
    "            EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "        )\n",
    "    html = driver.page_source\n",
    "    cont = str(html.encode('utf-8'))\n",
    "    soupCont = BeautifulSoup(cont)\n",
    "except Exception as e:\n",
    "    f=open(\"ETTodayException.log\",\"a\")\n",
    "    ExList=[\n",
    "        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "        \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "        \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "        \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "        \"\\t -Exception Traceback:\", \n",
    "        traceback.format_exc() + \"\\n\"\n",
    "    ]\n",
    "    f.writelines(ExList)\n",
    "    f.close\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments=[]\n",
    "commLink0 = soupCont.find(\"div\",re.compile('fb-comments.*'))\n",
    "commLink1= commLink0.select(' span > iframe')[0]['src']\n",
    "commLink=re.sub(r\"numposts=\\d{1,3}&\", \"numposts=100&\", commLink1)\n",
    "resComm = requests.get(commLink)\n",
    "resComm.encoding = \"utf-8\"\n",
    "soupComm = BeautifulSoup(resComm.text)      \n",
    "commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "for comm in commentBlock: \n",
    "    dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "    commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "    commentTime=dt.group(4)\n",
    "    commenter=comm.select('.profileName')[0].text\n",
    "    commenterUrl=comm.select('.profileName')[0]['href']\n",
    "    comment=comm.select('.postText')[0].text\n",
    "    comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "\n",
    "conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "for c in comments:\n",
    "    print c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5]\n",
    "    insert_comments(conn,c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5])\n",
    "close(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Accept-Encoding'] = 'gzip, deflate, sdch'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Cache-Control'] = 'max-age=0'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.Connection'] = 'keep-alive'\n",
    "webdriver.DesiredCapabilities.PHANTOMJS['phantomjs.page.customHeaders.User-Agent'] = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://www.facebook.com/yijuamy.chen\"\n",
    "headers={\n",
    "':host':'www.facebook.com',\n",
    "':method':'GET',\n",
    "':path':'/yijuamy.chen',\n",
    "':scheme':'https',\n",
    "':version':'HTTP/1.1',\n",
    "'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "'accept-encoding':'gzip, deflate, sdch',\n",
    "'accept-language':'en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4',\n",
    "'cache-control':'max-age=0',\n",
    "'cookie':'datr=QBNeUwqI4S51V5AzGEoeCA1r; _ga=GA1.2.1275457108.1428803544; lu=TgMfpfq2tjUWZNCGMvAtPqgg; c_user=100000310235880; fr=0R1TtmugtGGZqdare.AWXzmmSln6UThlEI7X7DWth-8LI.BT6iv-.MD.FV-.0.AWXKXYOq; xs=46%3AcvZCripsh73rfw%3A2%3A1434196224%3A14635; csm=2; s=Aa5VbbutJxLdjkjE.BVfBkA; act=1434791149057%2F13; p=-2; presence=EM434791329EuserFA21B00310235880A2EstateFDsb2F0Et2F_5b_5dElm2FnullEuct2F1434788575BEtrFA2loadA2EtwF2521827791EatF1434791328792G434791159662CEchFDp_5f1B00310235880F0CC; wd=1239x259',\n",
    "'referer':'https://www.facebook.com/plugins/comments.php?api_key=146858218737386&channel_url=http%3A%2F%2Fstatic.ak.facebook.com%2Fconnect%2Fxd_arbiter%2F1ldYU13brY_.js%3Fversion%3D41%23cb%3Df3be262b0c%26domain%3Dwww.ettoday.net%26origin%3Dhttp%253A%252F%252Fwww.ettoday.net%252Ffc8173f04%26relation%3Dparent.parent&colorscheme=light&href=http%3A%2F%2Fwww.ettoday.net%2Fnews%2F20150612%2F520021.htm&locale=zh_TW&numposts=10&sdk=joey&skin=light&version=v2.0&width=620',\n",
    "'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
