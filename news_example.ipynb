{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##推薦作法:\n",
    "- 將需要的資料都存成變數：\n",
    "    - 新聞內容：class(python裡class是保留字，所以我在下面的code改成category),title,newsDate,journalist,content,hit,url,source\n",
    "    - 評論：url,commenter,comment\n",
    "- 將這些變數用list或dictionary存起來\n",
    "- 將存的list或dictionary轉成pandas\n",
    "- 直接用DataFrame.to_csv(filename,encoding=\"utf-8\")轉成csv\n",
    "- 下面的code有存進資料庫的部分，如果不存資料庫的人可以把那些註解掉，存成csv就好，如果要存進資料庫，則記得先見好資料庫，資料庫的code詳見news.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一日期或日期區間  ETToday_day(startday,endday,sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# startday, endday 要輸入string(ex. '2015-1-1')\n",
    "# 沒輸入日期預設抓取昨天新聞\n",
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,journalist=None,content=None,hit=None,url=None,source=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(url,commenter,comment)values(%s,%s,%s)\" ,[url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "    \n",
    "sentinel = object()\n",
    "def ETToday_day(startday=(str(date.today()-timedelta(1))),endday=sentinel,sleep_time=0):\n",
    "     \n",
    "    if endday is sentinel:\n",
    "        endday=startday\n",
    "    \n",
    "    def convert_day(d):\n",
    "        return datetime.strptime(d, '%Y-%m-%d')\n",
    "    \n",
    "    ed=convert_day(endday)\n",
    "    sd=convert_day(startday)\n",
    "\n",
    "    assert ed >= sd, \"endday must after startday\"\n",
    "\n",
    "    ds = []\n",
    "    for i in xrange(0,(ed-sd).days+1):\n",
    "        ds.append(str((ed- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "    \n",
    "    for day in ds:\n",
    "        urls_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%day,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%day,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%day,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%day,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%day,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%day,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%day,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%day\n",
    "                   }\n",
    "\n",
    "        L = []\n",
    "        for url in urls_dic:\n",
    "            res = requests.get(urls_dic[url])\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                title=block.select('a')[0].text\n",
    "                aLink=block.select('a')[0]['href']\n",
    "                content = soup.select('.story > sectione > p')[1:]\n",
    "                for i in xrange(0,len(content)):\n",
    "                    for con in content[i].select('img'):\n",
    "                        content[i].img.decompose()\n",
    "                jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                #################連資料庫用\n",
    "                connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                insert_news()\n",
    "                close()\n",
    "                connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                insert_comments()\n",
    "                close()\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            if pageCount > 1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    url_1=str(urls_dic[url]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(url_1)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soup = BeautifulSoup(res.text)\n",
    "                    for block in soup.select(\"#all-news-list > h3\"):\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                        content = soup.select('.story > sectione > p')[1:]\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                        jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                        journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                        L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                        #################連資料庫用\n",
    "                        connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                        insert_news()\n",
    "                        close()\n",
    "                        connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                        insert_comments()\n",
    "                        close()\n",
    "                        #################連資料庫用\n",
    "                        time.sleep(sleep_time)\n",
    "            \n",
    "    # pandas\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(L,columns =['Category','Title','Content','Journalist','Link','Time','Source'])\n",
    "\n",
    "    # write in csv\n",
    "    if startday==endday:\n",
    "        std=\"\".join(startday.split('-'))\n",
    "        filename=\"ETToday\"+\"_\"+std+\".csv\"\n",
    "    else:\n",
    "        std=\"\".join(startday.split('-'))\n",
    "        end=\"\".join(endday.split('-'))\n",
    "        filename=\"ETToday\"+\"_\"+std+\"-\"+end+\".csv\"\n",
    "    print filename\n",
    "    f=open(filename,\"w\")\n",
    "    df.to_csv(filename,encoding=\"utf-8\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be string, not object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-39264dc76bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mETToday_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2015-06-04'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-f6fb6fdc9ece>\u001b[0m in \u001b[0;36mETToday_day\u001b[0;34m(startday, endday, sleep_time)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0med\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0msd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f6fb6fdc9ece>\u001b[0m in \u001b[0;36mconvert_day\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be string, not object"
     ]
    }
   ],
   "source": [
    "# run\n",
    "ETToday_day('2015-06-04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一或多月份  ETToday_month(year,month,year2,month2,sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "# year, month要輸入integer(ex. 2012,3)\n",
    "# 如果抓本月的新聞，會預設抓到今天前一天的新聞\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import calendar\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,journalist=None,content=None,hit=None,url=None,source=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(url,commenter,comment)values(%s,%s,%s)\" ,[url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "\n",
    "sentinel = object()\n",
    "def ETToday_month(year,month,year2=sentinel,month2=sentinel,sleep_time=0):\n",
    "    \n",
    "    if year2 is sentinel:\n",
    "        year2 = year\n",
    "    if month2 is sentinel:\n",
    "        month2 = month\n",
    "    \n",
    "    assert date(year2,month2,1)>=date(year,month,1), \"year2,month2 must after year,month\"\n",
    "\n",
    "    def first_day_of_month_d(d):\n",
    "        return date(d.year, d.month, 1)\n",
    "\n",
    "    def first_day_of_month(y,m):\n",
    "        return date(y,m,1)\n",
    "\n",
    "    def last_day_of_month(y,m):\n",
    "        return date(y,m+1,1) - timedelta(days = 1)\n",
    "\n",
    "    def diff_months_d(d1, d2):\n",
    "        return (d1.year - d2.year)*12 + d1.month - d2.month\n",
    "\n",
    "    def diff_days(y,m,y2,m2):\n",
    "        return abs(last_day_of_month(y2,m2)-first_day_of_month(y,m)).days\n",
    "\n",
    "    # check if input month exceed current month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year,month))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year2,month2))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month2\n",
    "\n",
    "    if diff_months_d(date.today(),first_day_of_month(year2,month2))==0:\n",
    "        duration=(date.today()-first_day_of_month_d(date.today())).days\n",
    "        ds = []\n",
    "        for i in xrange(1,duration+1):\n",
    "            ds.append(str((date.today()- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "    else:\n",
    "        #duration=calendar.monthrange(year,month)[1]\n",
    "        duration=diff_days(year,month,year2,month2)\n",
    "        ds = []\n",
    "        for i in xrange(0,duration+1):\n",
    "            ds.append(str((last_day_of_month(year2,month2)- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "\n",
    "    for day in ds:\n",
    "        urls_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%day,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%day,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%day,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%day,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%day,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%day,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%day,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%day\n",
    "                   }\n",
    "\n",
    "        L = []\n",
    "        for url in urls_dic:\n",
    "            res = requests.get(urls_dic[url])\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                title=block.select('a')[0].text\n",
    "                aLink=block.select('a')[0]['href']\n",
    "                content = soup.select('.story > sectione > p')[1:]\n",
    "                for i in xrange(0,len(content)):\n",
    "                    for con in content[i].select('img'):\n",
    "                        content[i].img.decompose()\n",
    "                jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                #################連資料庫用\n",
    "                connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                insert_news()\n",
    "                close()\n",
    "                connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                insert_comments()\n",
    "                close()\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            if pageCount > 1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    url_1=str(urls_dic[url]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(url_1)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soup = BeautifulSoup(res.text)\n",
    "                    for block in soup.select(\"#all-news-list > h3\"):\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                        content = soup.select('.story > sectione > p')[1:]\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                        jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                        journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                        L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                        #################連資料庫用\n",
    "                        connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                        insert_news()\n",
    "                        close()\n",
    "                        connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                        insert_comments()\n",
    "                        close()\n",
    "                        #################連資料庫用\n",
    "                        time.sleep(sleep_time)\n",
    "            \n",
    "    # pandas\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(L,columns =['Category','Title','Content','Journalist','Link','Time','Source'])\n",
    "\n",
    "    # write in csv\n",
    "    if (str(year)+str(month))==(str(year2)+str(month2)):\n",
    "        filename=\"ETTdoay_%d%02d.csv\"%(year,month)\n",
    "    else:\n",
    "        filename=\"ETTdoay_%d%02d-%d%02d.csv\"%(year,month,year2,month2)\n",
    "    f=open(filename,\"w\")\n",
    "    df.to_csv(filename,encoding=\"utf-8\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run\n",
    "ETToday_month(2015,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##直接輸入從今天算起要抓幾天 ETToday(days,sleep_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,comment,url)values(%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "    \n",
    "def ETToday(days,sleep_time=0,category=[\"政治\",\"財經\",\"國際\",\"大陸\"]):\n",
    "    #day = str(date.today()- timedelta(1))\n",
    "    \n",
    "    hit = None\n",
    "    ds = []\n",
    "    for i in xrange(1,days+1):\n",
    "        ds.append(str(date.today()- timedelta(i)))\n",
    "    \n",
    "    for day in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%day,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%day,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%day,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%day,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%day,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%day,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%day,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%day\n",
    "                   }\n",
    "        \n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            url_categories[cat]=url_dic[cat]\n",
    "\n",
    "        L = []\n",
    "        for cat in url_categories:\n",
    "            res = requests.get(url_categories[cat])\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "\n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                title=block.select('a')[0].text\n",
    "                aLink=block.select('a')[0]['href']\n",
    "                driver = webdriver.PhantomJS()\n",
    "                driver.get(aLink)\n",
    "                \n",
    "                #########get page breakpoint\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                            EC.visibility_of_element_located((By.CLASS_NAME, \"story\"))\n",
    "                        )\n",
    "                    html = driver.page_source\n",
    "                    cont = str(html.encode('utf-8'))\n",
    "                    soupCont = BeautifulSoup(cont)\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + day + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                finally:\n",
    "                    driver.quit()\n",
    "                #########get page breakpoint\n",
    "                \n",
    "                #########content breakpoint\n",
    "                try:\n",
    "                    content = soupCont.select('.story > sectione > p')[1:]\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + day + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########content breakpoint\n",
    "                \n",
    "                try:\n",
    "                    for i in xrange(0,len(content)):\n",
    "                        for con in content[i].select('img'):\n",
    "                            content[i].img.decompose()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                #########journist breakpoint\n",
    "                try:\n",
    "                    try:\n",
    "                        journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                    except:\n",
    "                        pass\n",
    "                except Exception as e:\n",
    "                    f=open(\"ETTodayException.log\",\"a\")\n",
    "                    ExList=[\n",
    "                        \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                        \"\\t -News Date: \" + day + \"\\n\",\n",
    "                        \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                        \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                        \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                        \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                        \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                    ]\n",
    "                    f.writelines(ExList)\n",
    "                    f.close\n",
    "                #########journist breakpoint\n",
    "                \n",
    "                #########category breakpoint\n",
    "                category=block.select('em')[0].text\n",
    "                if not category == cat:\n",
    "                    try:\n",
    "                        raise Exception\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + day + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                #########category breakpoint\n",
    "                \n",
    "                L.append({'Category':category,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                \n",
    "                #################連資料庫用\n",
    "                conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                insert_news(conn)\n",
    "                #insert_comments(conn)\n",
    "                close(conn)\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            if pageCount > 1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    cat_1=str(url_categories[cat]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(cat_1)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soup = BeautifulSoup(res.text)\n",
    "                    for block in soup.select(\"#all-news-list > h3\"):\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                        driver = webdriver.PhantomJS()\n",
    "                        driver.get(aLink)\n",
    "                        \n",
    "                        #########get page breakpoint\n",
    "                        try:\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                    EC.visibility_of_element_located((By.CLASS_NAME, \"story\"))\n",
    "                                )\n",
    "                            html = driver.page_source\n",
    "                            cont = str(html.encode('utf-8'))\n",
    "                            soupCont = BeautifulSoup(cont)\n",
    "                        except Exception as e:\n",
    "                            f=open(\"ETTodayException.log\",\"a\")\n",
    "                            ExList=[\n",
    "                                \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                                \"\\t -News Date: \" + day + \"\\n\",\n",
    "                                \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                                \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                                \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                                \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                                \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                            ]\n",
    "                            f.writelines(ExList)\n",
    "                            f.close\n",
    "                        finally:\n",
    "                            driver.quit()\n",
    "                        #########get page breakpoint    \n",
    "                            \n",
    "                        #########content breakpoint\n",
    "                        try:\n",
    "                            content = soupCont.select('.story > sectione > p')[1:]\n",
    "                        except Exception as e:\n",
    "                            f=open(\"ETTodayException.log\",\"a\")\n",
    "                            ExList=[\n",
    "                                \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                                \"\\t -News Date: \" + day + \"\\n\",\n",
    "                                \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                                \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                                \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                                \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                                \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                            ]\n",
    "                            f.writelines(ExList)\n",
    "                            f.close\n",
    "                        #########content breakpoint\n",
    "                        \n",
    "                        try:\n",
    "                            for i in xrange(0,len(content)):\n",
    "                                for con in content[i].select('img'):\n",
    "                                    content[i].img.decompose()\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        #########journist breakpoint\n",
    "                        try:\n",
    "                            try:\n",
    "                                journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                            except:\n",
    "                                pass\n",
    "                            try:\n",
    "                                journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                            except:\n",
    "                                pass\n",
    "                        except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + day + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                        #########journist breakpoint\n",
    "                        \n",
    "                        category=block.select('em')[0].text\n",
    "                        L.append({'Category':category,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                        \n",
    "                        #################連資料庫用\n",
    "                        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                        insert_news(conn,category,title,day,journalist,content,hit,alink)\n",
    "                        #insert_comments(conn)\n",
    "                        close(conn)\n",
    "                        #################連資料庫用\n",
    "                        time.sleep(sleep_time)\n",
    "            \n",
    "    # pandas\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(L,columns =['Category','Title','Content','Journalist','Link','Time','Source'])\n",
    "\n",
    "    # write in csv\n",
    "    f=open(\"ETToday.csv\",\"w\")\n",
    "    df.to_csv(\"ETToday\",encoding=\"utf-8\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nScreenshot: available via screen\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-397-da19b53891a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mETToday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-396-3b948fb897cb>\u001b[0m in \u001b[0;36mETToday\u001b[0;34m(days, sleep_time)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     WebDriverWait(driver, 10).until(\n\u001b[0;32m---> 65\u001b[0;31m                             \u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisibility_of_element_located\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"story\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                         )\n\u001b[1;32m     67\u001b[0m                     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/selenium/webdriver/support/wait.pyc\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nScreenshot: available via screen\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "ETToday(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=title,newsDate=day,journalist=journalist,content=content,hit=hit,url=aLink,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(url,commenter,comment)values(%s,%s,%s)\" ,[url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(%s,%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,commenter,commenterUrl,comment,url])\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,url,newsRaw):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into newsRaw(url,newsRaw)values(%s,%s)\",[url,newsRaw])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "    \n",
    "def ETToday(days=1,sleep_time=0,category=[\"政治\",\"財經\",\"國際\",\"大陸\"]):\n",
    "    \n",
    "    ds = []\n",
    "    for i in xrange(1,days+1):\n",
    "        ds.append(str(date.today()- timedelta(i)))\n",
    "    \n",
    "    for newsDate in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%newsDate,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%newsDate,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%newsDate,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%newsDate,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%newsDate,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%newsDate,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%newsDate,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%newsDate\n",
    "                   }\n",
    "        \n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            url_categories[cat]=url_dic[cat]\n",
    "\n",
    "        L = []\n",
    "        for cat in url_categories:\n",
    "            try:\n",
    "                res = requests.get(url_categories[cat])\n",
    "                res.encoding=\"utf-8\"\n",
    "                soup = BeautifulSoup(res.text)\n",
    "                page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "                pageCount = int(math.ceil(float(page)/30))\n",
    "                soups = [soup]\n",
    "            except:\n",
    "                print url_categories[cat]\n",
    "                raise \n",
    "            if pageCount >1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    curl = str(url_categories[cat]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(curl)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soups.append(BeautifulSoup(res.text))\n",
    "\n",
    "            for soup in soups:         \n",
    "                for block in soup.select(\"#all-news-list > h3\"):\n",
    "                    try:\n",
    "                        timeRegex=re.search(\"\\[(\\d\\d)\\/(\\d\\d) (\\d{1,2}\\:\\d{1,2})\\]\",block.select('span')[0].text)\n",
    "                        testDate=timeRegex.group(1)+'-'+timeRegex.group(2)\n",
    "                        if not testDate == re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'):\n",
    "                            continue\n",
    "                        newsTime=timeRegex.group(3)\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                    except:\n",
    "                        print url_categories[cat]\n",
    "                        raise\n",
    "                    #########get page breakpoint\n",
    "                    #driver = webdriver.Firefox()\n",
    "                    driver = webdriver.Chrome()\n",
    "                    #driver = webdriver.PhantomJS()\n",
    "                    driver.get(aLink)\n",
    "                    try:\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                                EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "                            )\n",
    "                        html = driver.page_source\n",
    "                        cont = str(html.encode('utf-8'))\n",
    "                        soupCont = BeautifulSoup(cont)\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    finally:\n",
    "                        driver.quit()\n",
    "                    #########get page breakpoint\n",
    "\n",
    "                    #########content breakpoint\n",
    "                    try:\n",
    "                        content=\"\"\n",
    "                        contentRaw = soupCont.select('.story > sectione > p')\n",
    "                        for p in contentRaw:\n",
    "                            content = content + p.text\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########content breakpoint\n",
    "\n",
    "                    try:\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    #########journist breakpoint\n",
    "                    try:\n",
    "                        try:\n",
    "                            journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########journist breakpoint\n",
    "                    \n",
    "                    #########comment breakpoint\n",
    "                    comments=[]\n",
    "                    try:\n",
    "                        commLink = soupCont.select('.fb-comments.fb_iframe_widget > span > iframe')[0]['src']\n",
    "                        resComm = requests.get(commLink)\n",
    "                        resComm.encoding = \"utf-8\"\n",
    "                        soupComm = BeautifulSoup(resComm.text)      \n",
    "                        commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "                        for comm in commentBlock: \n",
    "                            dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "                            commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "                            commentTime=dt.group(4)\n",
    "                            commenter=comm.select('.profileName')[0].text\n",
    "                            commenterUrl=comm.select('.profileName')[0]['href']\n",
    "                            comment=comm.select('.postText')[0].text\n",
    "                            comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: comment\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########comment breakpoint\n",
    "\n",
    "                    #########category breakpoint\n",
    "                    category=block.select('em')[0].text\n",
    "                    if not category == cat.decode(\"utf-8\"):\n",
    "                        try:\n",
    "                            raise Exception\n",
    "                        except Exception as e:\n",
    "                            f=open(\"ETTodayException.log\",\"a\")\n",
    "                            ExList=[\n",
    "                                \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                                \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                                \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                                \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                                \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                                \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                                \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "                            ]\n",
    "                            f.writelines(ExList)\n",
    "                            f.close\n",
    "                    #########category breakpoint\n",
    "    \n",
    "                    try:\n",
    "                        L.append({'class':category,'title':title,'newsDate':newsDate,'newsTime':newsTime,'journalist':journalist,'content':content,'hit':hit,'url':aLink,'source':'ETToday'})\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    #################連資料庫用\n",
    "                    hit = None\n",
    "                    #print category,title,newsDate,newsTime,journalist,content,hit,aLink,commentDate,commentTime,commenter,comment\n",
    "                    try:\n",
    "                        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                        insert_news(conn,category,title,newsDate,newsTime,journalist,content[0],hit,aLink)\n",
    "                        insert_comments(conn,commentDate,commentTime,commenter,commenterUrl,comment,aLink)\n",
    "                        insert_newsRaw(conn,aLink,res.text)\n",
    "                        close(conn)\n",
    "                    except:\n",
    "                        print \"nothing write in DB\"\n",
    "                    #################連資料庫用\n",
    "                    time.sleep(sleep_time)\n",
    "    \n",
    "    \n",
    "    #########write_in_csv breakpoint\n",
    "    try:\n",
    "        # pandas - content\n",
    "        df = pd.DataFrame(L,columns =['class','title','newsDate','newsTime','journalist','content','hit','url','source'])\n",
    "        # pandas - comment\n",
    "        df_comm = pd.DataFrame(comments,columns =['commentDate','commentTime','commenter','commenterUrl','comment','url'])\n",
    "\n",
    "        # write content in csv\n",
    "        f=open(\"ETToday_content.csv\",\"w\")\n",
    "        df.to_csv(\"ETToday_content.csv\",encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        # write comment in csv\n",
    "        f=open(\"ETToday_comment.csv\",\"w\")\n",
    "        df_comm.to_csv(\"ETToday_comment.csv\",encoding=\"utf-8\")\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        f=open(\"ETTodayException.log\",\"a\")\n",
    "        ExList=[\n",
    "            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "            \"\\t -BreakPoint: write_in_csv\" + \"\\n\",\n",
    "            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "            \"\\t -Exception Message: \" + e.message + \"\\n\"\n",
    "        ]\n",
    "        f.writelines(ExList)\n",
    "        f.close\n",
    "#########write_in_csv breakpoint\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n",
      "nothing write in DB\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-b511d23dc748>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mETToday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"政治\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-68713a532fc3>\u001b[0m in \u001b[0;36mETToday\u001b[0;34m(days, sleep_time, category)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#all-news-list > h3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0maLink\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'href'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "ETToday(category=[\"政治\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testDate[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://www.facebook.com/yijuamy.chen\"\n",
    "headers={\n",
    "':host':'www.facebook.com',\n",
    "':method':'GET',\n",
    "':path':'/yijuamy.chen',\n",
    "':scheme':'https',\n",
    "':version':'HTTP/1.1',\n",
    "'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "'accept-encoding':'gzip, deflate, sdch',\n",
    "'accept-language':'en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4',\n",
    "'cache-control':'max-age=0',\n",
    "'cookie':'datr=QBNeUwqI4S51V5AzGEoeCA1r; _ga=GA1.2.1275457108.1428803544; lu=TgMfpfq2tjUWZNCGMvAtPqgg; c_user=100000310235880; fr=0R1TtmugtGGZqdare.AWXzmmSln6UThlEI7X7DWth-8LI.BT6iv-.MD.FV-.0.AWXKXYOq; xs=46%3AcvZCripsh73rfw%3A2%3A1434196224%3A14635; csm=2; s=Aa5VbbutJxLdjkjE.BVfBkA; act=1434791149057%2F13; p=-2; presence=EM434791329EuserFA21B00310235880A2EstateFDsb2F0Et2F_5b_5dElm2FnullEuct2F1434788575BEtrFA2loadA2EtwF2521827791EatF1434791328792G434791159662CEchFDp_5f1B00310235880F0CC; wd=1239x259',\n",
    "'referer':'https://www.facebook.com/plugins/comments.php?api_key=146858218737386&channel_url=http%3A%2F%2Fstatic.ak.facebook.com%2Fconnect%2Fxd_arbiter%2F1ldYU13brY_.js%3Fversion%3D41%23cb%3Df3be262b0c%26domain%3Dwww.ettoday.net%26origin%3Dhttp%253A%252F%252Fwww.ettoday.net%252Ffc8173f04%26relation%3Dparent.parent&colorscheme=light&href=http%3A%2F%2Fwww.ettoday.net%2Fnews%2F20150612%2F520021.htm&locale=zh_TW&numposts=10&sdk=joey&skin=light&version=v2.0&width=620',\n",
    "'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
