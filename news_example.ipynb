{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##推薦作法:\n",
    "- 將需要的資料都存成變數：\n",
    "    - 新聞內容：class(python裡class是保留字，所以我在下面的code改成category),title,newsDate,journalist,content,hit,url,source\n",
    "    - 評論：url,commenter,comment\n",
    "- 將這些變數用list或dictionary存起來\n",
    "- 將存的list或dictionary轉成pandas\n",
    "- 直接用DataFrame.to_csv(filename,encoding=\"utf-8\")轉成csv\n",
    "- 下面的code有存進資料庫的部分，如果不存資料庫的人可以把那些註解掉，存成csv就好，如果要存進資料庫，則記得先見好資料庫，資料庫的code詳見news.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一日期或日期區間  ETToday_day(startday,endday,sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# startday, endday 要輸入string(ex. '2015-1-1')\n",
    "# 沒輸入日期預設抓取昨天新聞\n",
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,journalist=None,content=None,hit=None,url=None,source=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(url,commenter,comment)values(%s,%s,%s)\" ,[url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "    \n",
    "sentinel = object()\n",
    "def ETToday_day(startday=(str(date.today()-timedelta(1))),endday=sentinel,sleep_time=0):\n",
    "     \n",
    "    if endday is sentinel:\n",
    "        endday=startday\n",
    "    \n",
    "    def convert_day(d):\n",
    "        return datetime.strptime(d, '%Y-%m-%d')\n",
    "    \n",
    "    ed=convert_day(endday)\n",
    "    sd=convert_day(startday)\n",
    "\n",
    "    assert ed >= sd, \"endday must after startday\"\n",
    "\n",
    "    ds = []\n",
    "    for i in xrange(0,(ed-sd).days+1):\n",
    "        ds.append(str((ed- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "    \n",
    "    for day in ds:\n",
    "        urls_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%day,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%day,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%day,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%day,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%day,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%day,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%day,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%day\n",
    "                   }\n",
    "\n",
    "        L = []\n",
    "        for url in urls_dic:\n",
    "            res = requests.get(urls_dic[url])\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                title=block.select('a')[0].text\n",
    "                aLink=block.select('a')[0]['href']\n",
    "                content = soup.select('.story > sectione > p')[1:]\n",
    "                for i in xrange(0,len(content)):\n",
    "                    for con in content[i].select('img'):\n",
    "                        content[i].img.decompose()\n",
    "                jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                #################連資料庫用\n",
    "                connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                insert_news()\n",
    "                close()\n",
    "                connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                insert_comments()\n",
    "                close()\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            if pageCount > 1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    url_1=str(urls_dic[url]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(url_1)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soup = BeautifulSoup(res.text)\n",
    "                    for block in soup.select(\"#all-news-list > h3\"):\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                        content = soup.select('.story > sectione > p')[1:]\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                        jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                        journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                        L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                        #################連資料庫用\n",
    "                        connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                        insert_news()\n",
    "                        close()\n",
    "                        connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                        insert_comments()\n",
    "                        close()\n",
    "                        #################連資料庫用\n",
    "                        time.sleep(sleep_time)\n",
    "            \n",
    "    # pandas\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(L,columns =['Category','Title','Content','Journalist','Link','Time','Source'])\n",
    "\n",
    "    # write in csv\n",
    "    if startday==endday:\n",
    "        std=\"\".join(startday.split('-'))\n",
    "        filename=\"ETToday\"+\"_\"+std+\".csv\"\n",
    "    else:\n",
    "        std=\"\".join(startday.split('-'))\n",
    "        end=\"\".join(endday.split('-'))\n",
    "        filename=\"ETToday\"+\"_\"+std+\"-\"+end+\".csv\"\n",
    "    print filename\n",
    "    f=open(filename,\"w\")\n",
    "    df.to_csv(filename,encoding=\"utf-8\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be string, not object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-39264dc76bf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mETToday_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2015-06-04'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-f6fb6fdc9ece>\u001b[0m in \u001b[0;36mETToday_day\u001b[0;34m(startday, endday, sleep_time)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0med\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0msd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f6fb6fdc9ece>\u001b[0m in \u001b[0;36mconvert_day\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0med\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be string, not object"
     ]
    }
   ],
   "source": [
    "# run\n",
    "ETToday_day('2015-06-04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一或多月份  ETToday_month(year,month,year2,month2,sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "# year, month要輸入integer(ex. 2012,3)\n",
    "# 如果抓本月的新聞，會預設抓到今天前一天的新聞\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import calendar\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,journalist=None,content=None,hit=None,url=None,source=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(url,commenter,comment)values(%s,%s,%s)\" ,[url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "\n",
    "sentinel = object()\n",
    "def ETToday_month(year,month,year2=sentinel,month2=sentinel,sleep_time=0):\n",
    "    \n",
    "    if year2 is sentinel:\n",
    "        year2 = year\n",
    "    if month2 is sentinel:\n",
    "        month2 = month\n",
    "    \n",
    "    assert date(year2,month2,1)>=date(year,month,1), \"year2,month2 must after year,month\"\n",
    "\n",
    "    def first_day_of_month_d(d):\n",
    "        return date(d.year, d.month, 1)\n",
    "\n",
    "    def first_day_of_month(y,m):\n",
    "        return date(y,m,1)\n",
    "\n",
    "    def last_day_of_month(y,m):\n",
    "        return date(y,m+1,1) - timedelta(days = 1)\n",
    "\n",
    "    def diff_months_d(d1, d2):\n",
    "        return (d1.year - d2.year)*12 + d1.month - d2.month\n",
    "\n",
    "    def diff_days(y,m,y2,m2):\n",
    "        return abs(last_day_of_month(y2,m2)-first_day_of_month(y,m)).days\n",
    "\n",
    "    # check if input month exceed current month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year,month))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year2,month2))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month2\n",
    "\n",
    "    if diff_months_d(date.today(),first_day_of_month(year2,month2))==0:\n",
    "        duration=(date.today()-first_day_of_month_d(date.today())).days\n",
    "        ds = []\n",
    "        for i in xrange(1,duration+1):\n",
    "            ds.append(str((date.today()- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "    else:\n",
    "        #duration=calendar.monthrange(year,month)[1]\n",
    "        duration=diff_days(year,month,year2,month2)\n",
    "        ds = []\n",
    "        for i in xrange(0,duration+1):\n",
    "            ds.append(str((last_day_of_month(year2,month2)- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "\n",
    "    for day in ds:\n",
    "        urls_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%day,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%day,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%day,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%day,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%day,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%day,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%day,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%day\n",
    "                   }\n",
    "\n",
    "        L = []\n",
    "        for url in urls_dic:\n",
    "            res = requests.get(urls_dic[url])\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                title=block.select('a')[0].text\n",
    "                aLink=block.select('a')[0]['href']\n",
    "                content = soup.select('.story > sectione > p')[1:]\n",
    "                for i in xrange(0,len(content)):\n",
    "                    for con in content[i].select('img'):\n",
    "                        content[i].img.decompose()\n",
    "                jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                #################連資料庫用\n",
    "                connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                insert_news()\n",
    "                close()\n",
    "                connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                insert_comments()\n",
    "                close()\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            if pageCount > 1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    url_1=str(urls_dic[url]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(url_1)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soup = BeautifulSoup(res.text)\n",
    "                    for block in soup.select(\"#all-news-list > h3\"):\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                        content = soup.select('.story > sectione > p')[1:]\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                        jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                        journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                        L.append({'Category':block.select('em')[0].text,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                        #################連資料庫用\n",
    "                        connect(\"news\",\"\",\"localhost\",\"root\")\n",
    "                        insert_news()\n",
    "                        close()\n",
    "                        connect(\"comments\",\"\",\"localhost\",\"root\")\n",
    "                        insert_comments()\n",
    "                        close()\n",
    "                        #################連資料庫用\n",
    "                        time.sleep(sleep_time)\n",
    "            \n",
    "    # pandas\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(L,columns =['Category','Title','Content','Journalist','Link','Time','Source'])\n",
    "\n",
    "    # write in csv\n",
    "    if (str(year)+str(month))==(str(year2)+str(month2)):\n",
    "        filename=\"ETTdoay_%d%02d.csv\"%(year,month)\n",
    "    else:\n",
    "        filename=\"ETTdoay_%d%02d-%d%02d.csv\"%(year,month,year2,month2)\n",
    "    f=open(filename,\"w\")\n",
    "    df.to_csv(filename,encoding=\"utf-8\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run\n",
    "ETToday_month(2015,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##直接輸入從今天算起要抓幾天 ETToday(days,sleep_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(url,commenter,comment)values(%s,%s,%s)\" ,[url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "    \n",
    "def ETToday(days,sleep_time=0):\n",
    "    #day = str(date.today()- timedelta(1))\n",
    "    \n",
    "    hit = None\n",
    "    ds = []\n",
    "    for i in xrange(1,days+1):\n",
    "        ds.append(str(date.today()- timedelta(i)))\n",
    "    \n",
    "    for day in ds:\n",
    "        urls_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%day,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%day,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%day,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%day,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%day,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%day,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%day,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%day\n",
    "                   }\n",
    "\n",
    "        L = []\n",
    "        for url in urls_dic:\n",
    "            res = requests.get(urls_dic[url])\n",
    "            res.encoding=\"utf-8\"\n",
    "            soup = BeautifulSoup(res.text)\n",
    "            page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "            pageCount = int(math.ceil(float(page)/30))\n",
    "            for block in soup.select(\"#all-news-list > h3\"):\n",
    "                title=block.select('a')[0].text\n",
    "                aLink=block.select('a')[0]['href']\n",
    "                driver = webdriver.PhantomJS()\n",
    "                driver.get(aLink)\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(\n",
    "                            EC.visibility_of_element_located((By.CLASS_NAME, \"story\"))\n",
    "                        )\n",
    "                    html = driver.page_source\n",
    "                    cont = str(html.encode('utf-8'))\n",
    "                    soupCont = BeautifulSoup(cont)\n",
    "                finally:\n",
    "                    driver.quit()\n",
    "                content = soupCont.select('.story > sectione > p')[1:]\n",
    "                for i in xrange(0,len(content)):\n",
    "                    for con in content[i].select('img'):\n",
    "                        content[i].img.decompose()\n",
    "                try:\n",
    "                    journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                except:\n",
    "                    pass\n",
    "                category=block.select('em')[0].text\n",
    "                #jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                #journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                L.append({'Category':category,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                #################連資料庫用\n",
    "                conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                insert_news(conn)\n",
    "                #insert_comments(conn)\n",
    "                close(conn)\n",
    "                #################連資料庫用\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            if pageCount > 1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    url_1=str(urls_dic[url]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(url_1)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soup = BeautifulSoup(res.text)\n",
    "                    for block in soup.select(\"#all-news-list > h3\"):\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                        driver = webdriver.PhantomJS()\n",
    "                        driver.get(aLink)\n",
    "                        try:\n",
    "                            WebDriverWait(driver, 10).until(\n",
    "                                    EC.visibility_of_element_located((By.CLASS_NAME, \"story\"))\n",
    "                                )\n",
    "                            html = driver.page_source\n",
    "                            cont = str(html.encode('utf-8'))\n",
    "                            soupCont = BeautifulSoup(cont)\n",
    "                        finally:\n",
    "                            driver.quit()\n",
    "                        content = soupCont.select('.story > sectione > p')[1:]\n",
    "                        try:\n",
    "                            for i in xrange(0,len(content)):\n",
    "                                for con in content[i].select('img'):\n",
    "                                    content[i].img.decompose()\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                        #jour = str(soup.select('.story > sectione > p')[0].text.encode('utf-8'))\n",
    "                        #journalist = (jour.split(\"記者\")[1]).split(\"／\")[0]\n",
    "                        category=block.select('em')[0].text\n",
    "                        L.append({'Category':category,'Title':title,'Content':content,'Journalist':journalist,'Link':aLink,'Time':day,'Source':'ETToday'})\n",
    "                        #################連資料庫用\n",
    "                        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                        insert_news(conn,category,title,day,journalist,content,hit,alink)\n",
    "                        #insert_comments(conn)\n",
    "                        close(conn)\n",
    "                        #################連資料庫用\n",
    "                        time.sleep(sleep_time)\n",
    "            \n",
    "    # pandas\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(L,columns =['Category','Title','Content','Journalist','Link','Time','Source'])\n",
    "\n",
    "    # write in csv\n",
    "    f=open(\"ETToday.csv\",\"w\")\n",
    "    df.to_csv(\"ETToday\",encoding=\"utf-8\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nScreenshot: available via screen\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-397-da19b53891a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mETToday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-396-3b948fb897cb>\u001b[0m in \u001b[0;36mETToday\u001b[0;34m(days, sleep_time)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     WebDriverWait(driver, 10).until(\n\u001b[0;32m---> 65\u001b[0;31m                             \u001b[0mEC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisibility_of_element_located\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"story\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                         )\n\u001b[1;32m     67\u001b[0m                     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/selenium/webdriver/support/wait.pyc\u001b[0m in \u001b[0;36muntil\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muntil_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nScreenshot: available via screen\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "ETToday(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'title' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-394-6a1bf40df246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMySQLdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpasswd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdbname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcharset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0minsert_news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewsDate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjournalist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjournalist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maLink\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ETToday\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewsDate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjournalist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'title' is not defined"
     ]
    }
   ],
   "source": [
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=title,newsDate=day,journalist=journalist,content=content,hit=hit,url=aLink,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,url,commenter,comment,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(url,commenter,comment)values(%s,%s,%s)\" ,[url,commenter,comment])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url=\"aaaa\"\n",
    "commenter=\"abb\"\n",
    "comment=\"cc\"\n",
    "a=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "insert_comments(a,url,commenter,comment)\n",
    "insert_news(a,\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\")\n",
    "close(a)\n",
    "#connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
