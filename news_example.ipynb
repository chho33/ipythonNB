{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##推薦作法:\n",
    "- 將需要的資料都存成變數：\n",
    "    - 新聞內容：class(python裡class是保留字，所以我在下面的code改成category),title,newsDate,journalist,content,hit,url,source\n",
    "    - 評論：url,commenter,comment\n",
    "- 將這些變數用list或dictionary存起來\n",
    "- 將存的list或dictionary轉成pandas\n",
    "- 直接用DataFrame.to_csv(filename,encoding=\"utf-8\")轉成csv\n",
    "- 下面的code有存進資料庫的部分，如果不存資料庫的人可以把那些註解掉，存成csv就好，如果要存進資料庫，則記得先見好資料庫，資料庫的code詳見news.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一日期或日期區間  ETToday_day(startday,endday,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "# year, month要輸入integer(ex. 2012,3)\n",
    "# 如果抓本月的新聞，會預設抓到今天前一天的新聞\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import traceback\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(%s,%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,commenter,commenterUrl,comment,url])\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,url,newsRaw):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into newsRaw(url,newsRaw)values(%s,%s)\",[url,newsRaw])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "\n",
    "sentinel = object()\n",
    "def ETToday_day(startday=(str(date.today()-timedelta(1))),endday=sentinel,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0):\n",
    "     \n",
    "    if endday is sentinel:\n",
    "        endday=startday\n",
    "    \n",
    "    def convert_day(d):\n",
    "        return datetime.strptime(d, '%Y-%m-%d')\n",
    "    \n",
    "    ed=convert_day(endday)\n",
    "    sd=convert_day(startday)\n",
    "\n",
    "    assert ed >= sd, \"endday must after startday\"\n",
    "\n",
    "    ds = []\n",
    "    for i in xrange(0,(ed-sd).days+1):\n",
    "        ds.append(str((ed- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "\n",
    "    for newsDate in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%newsDate,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%newsDate,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%newsDate,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%newsDate,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%newsDate,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%newsDate,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%newsDate,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%newsDate\n",
    "                   }\n",
    "        \n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            url_categories[cat]=url_dic[cat]\n",
    "\n",
    "        L = []\n",
    "        for cat in url_categories:\n",
    "            try:\n",
    "                res = requests.get(url_categories[cat])\n",
    "                res.encoding=\"utf-8\"\n",
    "                soup = BeautifulSoup(res.text)\n",
    "                page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "                pageCount = int(math.ceil(float(page)/30))\n",
    "                soups = [soup]\n",
    "            except:\n",
    "                print url_categories[cat]\n",
    "                raise \n",
    "            if pageCount >1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    curl = str(url_categories[cat]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(curl)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soups.append(BeautifulSoup(res.text))\n",
    "\n",
    "            for soup in soups:         \n",
    "                for block in soup.select(\"#all-news-list > h3\"):\n",
    "                    try:\n",
    "                        timeRegex=re.search(\"\\[(\\d\\d)\\/(\\d\\d) (\\d{1,2}\\:\\d{1,2})\\]\",block.select('span')[0].text)\n",
    "                        testDate=timeRegex.group(1)+'-'+timeRegex.group(2)\n",
    "                        if not testDate == re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'):\n",
    "                            continue\n",
    "                        newsTime=timeRegex.group(3)\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                    except:\n",
    "                        print url_categories[cat]\n",
    "                        raise\n",
    "                    #########get page breakpoint\n",
    "                    driver = webdriver.Firefox()\n",
    "                    #driver = webdriver.Chrome()\n",
    "                    #driver = webdriver.PhantomJS()\n",
    "                    driver.get(aLink)\n",
    "                    try:\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                                EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "                            )\n",
    "                        html = driver.page_source\n",
    "                        cont = str(html.encode('utf-8'))\n",
    "                        soupCont = BeautifulSoup(cont)\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    finally:\n",
    "                        driver.quit()\n",
    "                    #########get page breakpoint\n",
    "\n",
    "                    #########content breakpoint\n",
    "                    try:\n",
    "                        content=\"\"\n",
    "                        contentRaw = soupCont.select('.story > sectione > p')\n",
    "                        for p in contentRaw:\n",
    "                            content = content + p.text\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########content breakpoint\n",
    "\n",
    "                    try:\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    #########journist breakpoint\n",
    "                    try:\n",
    "                        try:\n",
    "                            journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########journist breakpoint\n",
    "                    \n",
    "                    #########comment breakpoint\n",
    "                    comments=[]\n",
    "                    try:\n",
    "                        commLink1 = soupCont.select('.fb-comments.fb_iframe_widget > span > iframe')[0]['src']\n",
    "                        commLink=re.sub(r\"numposts=\\d{1,3}&\", \"numposts=100&\", commLink1)\n",
    "                        resComm = requests.get(commLink)\n",
    "                        resComm.encoding = \"utf-8\"\n",
    "                        soupComm = BeautifulSoup(resComm.text)      \n",
    "                        commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "                        for comm in commentBlock: \n",
    "                            dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "                            commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "                            commentTime=dt.group(4)\n",
    "                            commenter=comm.select('.profileName')[0].text\n",
    "                            commenterUrl=comm.select('.profileName')[0]['href']\n",
    "                            comment=comm.select('.postText')[0].text\n",
    "                            comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: comment\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########comment breakpoint\n",
    "\n",
    "                    #########category breakpoint\n",
    "                    category=block.select('em')[0].text\n",
    "                    if not category == cat.decode(\"utf-8\"):\n",
    "                        try:\n",
    "                            raise Exception\n",
    "                        except Exception as e:\n",
    "                            f=open(\"ETTodayException.log\",\"a\")\n",
    "                            ExList=[\n",
    "                                \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                                \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                                \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                                \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                                \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                                \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                                \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                                \"\\t -Exception Traceback:\", \n",
    "                                traceback.format_exc() + \"\\n\"\n",
    "                            ]\n",
    "                            f.writelines(ExList)\n",
    "                            f.close\n",
    "                    #########category breakpoint\n",
    "    \n",
    "                    try:\n",
    "                        L.append({'class':category,'title':title,'newsDate':newsDate,'newsTime':newsTime,'journalist':journalist,'content':content,'hit':hit,'url':aLink,'source':'ETToday'})\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    #################連資料庫用\n",
    "                    hit = None\n",
    "                    #print category,title,newsDate,newsTime,journalist,content,hit,aLink,commentDate,commentTime,commenter,comment\n",
    "                    try:\n",
    "                        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                        insert_news(conn,category,title,newsDate,newsTime,journalist,content[0],hit,aLink)\n",
    "                        #insert_comments(conn,commentDate,commentTime,commenter,commenterUrl,comment,aLink)\n",
    "                        insert_newsRaw(conn,aLink,res.text)\n",
    "                        close(conn)\n",
    "                    except:\n",
    "                        print \"nothing write in DB\"\n",
    "                    #################連資料庫用\n",
    "                    time.sleep(sleep_time)\n",
    "    \n",
    "    \n",
    "    #########write_in_csv breakpoint\n",
    "    try:\n",
    "        # pandas - content\n",
    "        df = pd.DataFrame(L,columns =['class','title','newsDate','newsTime','journalist','content','hit','url','source'])\n",
    "        # pandas - comment\n",
    "        df_comm = pd.DataFrame(comments,columns =['commentDate','commentTime','commenter','commenterUrl','comment','url','remark'])\n",
    "        \n",
    "        # comment into MySQL\n",
    "        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "        for c in comments:\n",
    "            insert_comments(conn,c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5])\n",
    "        close(conn)\n",
    "        \n",
    "        # write csv\n",
    "        if startday==endday:\n",
    "            std=\"\".join(startday.split('-'))\n",
    "            filename_content=\"ETTdoay_content_\"+std+\".csv\"\n",
    "            filename_comment=\"ETTdoay_comment_\"+std+\".csv\"\n",
    "        else:\n",
    "            std=\"\".join(startday.split('-'))\n",
    "            end=\"\".join(endday.split('-'))\n",
    "            filename_content=\"ETTdoay_content_\"+\"_\"+std+\"-\"+end+\".csv\"\n",
    "            filename_comment=\"ETTdoay_comment_\"+\"_\"+std+\"-\"+end+\".csv\"\n",
    "        ## write content in csv\n",
    "        f=open(filename_content,\"w\")\n",
    "        df.to_csv(filename_content,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        ## write comment in csv\n",
    "        f=open(filename_comment,\"w\")\n",
    "        df_comm.to_csv(filename_comment,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        f=open(\"ETTodayException.log\",\"a\")\n",
    "        ExList=[\n",
    "            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "            \"\\t -BreakPoint: write_in_csv\" + \"\\n\",\n",
    "            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "            \"\\t -Exception Traceback:\", \n",
    "            traceback.format_exc() + \"\\n\"\n",
    "        ]\n",
    "        f.writelines(ExList)\n",
    "        f.close\n",
    "#########write_in_csv breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run\n",
    "ETToday_day('2015-06-04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓取單一或多月份  ETToday_month(year,month,year2,month2,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sleep_time意思為抓取每一天新聞之間要休息多久，單位為秒\n",
    "# year, month要輸入integer(ex. 2012,3)\n",
    "# 如果抓本月的新聞，會預設抓到今天前一天的新聞\n",
    "\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import traceback\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(%s,%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,commenter,commenterUrl,comment,url])\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,url,newsRaw):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into newsRaw(url,newsRaw)values(%s,%s)\",[url,newsRaw])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "\n",
    "sentinel = object()\n",
    "def ETToday_month(year,month,year2=sentinel,month2=sentinel,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0):\n",
    "    \n",
    "    if year2 is sentinel:\n",
    "        year2 = year\n",
    "    if month2 is sentinel:\n",
    "        month2 = month\n",
    "    \n",
    "    assert date(year2,month2,1)>=date(year,month,1), \"year2,month2 must after year,month\"\n",
    "\n",
    "    def first_day_of_month_d(d):\n",
    "        return date(d.year, d.month, 1)\n",
    "\n",
    "    def first_day_of_month(y,m):\n",
    "        return date(y,m,1)\n",
    "\n",
    "    def last_day_of_month(y,m):\n",
    "        return date(y,m+1,1) - timedelta(days = 1)\n",
    "\n",
    "    def diff_months_d(d1, d2):\n",
    "        return (d1.year - d2.year)*12 + d1.month - d2.month\n",
    "\n",
    "    def diff_days(y,m,y2,m2):\n",
    "        return abs(last_day_of_month(y2,m2)-first_day_of_month(y,m)).days\n",
    "\n",
    "    # check if input month exceed current month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year,month))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month\n",
    "    assert diff_months_d(date.today(),first_day_of_month(year2,month2))>=0, \"眼睛睜大點好嘛？%s月還沒到ok？\"%month2\n",
    "\n",
    "    if diff_months_d(date.today(),first_day_of_month(year2,month2))==0:\n",
    "        duration=(date.today()-first_day_of_month_d(date.today())).days\n",
    "        ds = []\n",
    "        for i in xrange(1,duration+1):\n",
    "            ds.append(str((date.today()- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "    else:\n",
    "        #duration=calendar.monthrange(year,month)[1]\n",
    "        duration=diff_days(year,month,year2,month2)\n",
    "        ds = []\n",
    "        for i in xrange(0,duration+1):\n",
    "            ds.append(str((last_day_of_month(year2,month2)- timedelta(i)).strftime('%Y-%m-%d')))\n",
    "\n",
    "    for newsDate in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%newsDate,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%newsDate,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%newsDate,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%newsDate,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%newsDate,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%newsDate,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%newsDate,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%newsDate\n",
    "                   }\n",
    "        \n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            url_categories[cat]=url_dic[cat]\n",
    "\n",
    "        L = []\n",
    "        for cat in url_categories:\n",
    "            try:\n",
    "                res = requests.get(url_categories[cat])\n",
    "                res.encoding=\"utf-8\"\n",
    "                soup = BeautifulSoup(res.text)\n",
    "                page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "                pageCount = int(math.ceil(float(page)/30))\n",
    "                soups = [soup]\n",
    "            except:\n",
    "                print url_categories[cat]\n",
    "                raise \n",
    "            if pageCount >1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    curl = str(url_categories[cat]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(curl)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soups.append(BeautifulSoup(res.text))\n",
    "\n",
    "            for soup in soups:         \n",
    "                for block in soup.select(\"#all-news-list > h3\"):\n",
    "                    try:\n",
    "                        timeRegex=re.search(\"\\[(\\d\\d)\\/(\\d\\d) (\\d{1,2}\\:\\d{1,2})\\]\",block.select('span')[0].text)\n",
    "                        testDate=timeRegex.group(1)+'-'+timeRegex.group(2)\n",
    "                        if not testDate == re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'):\n",
    "                            continue\n",
    "                        newsTime=timeRegex.group(3)\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                    except:\n",
    "                        print url_categories[cat]\n",
    "                        raise\n",
    "                    #########get page breakpoint\n",
    "                    driver = webdriver.Firefox()\n",
    "                    #driver = webdriver.Chrome()\n",
    "                    #driver = webdriver.PhantomJS()\n",
    "                    driver.get(aLink)\n",
    "                    try:\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                                EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "                            )\n",
    "                        html = driver.page_source\n",
    "                        cont = str(html.encode('utf-8'))\n",
    "                        soupCont = BeautifulSoup(cont)\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    finally:\n",
    "                        driver.quit()\n",
    "                    #########get page breakpoint\n",
    "\n",
    "                    #########content breakpoint\n",
    "                    try:\n",
    "                        content=\"\"\n",
    "                        contentRaw = soupCont.select('.story > sectione > p')\n",
    "                        for p in contentRaw:\n",
    "                            content = content + p.text\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########content breakpoint\n",
    "\n",
    "                    try:\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    #########journist breakpoint\n",
    "                    try:\n",
    "                        try:\n",
    "                            journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########journist breakpoint\n",
    "                    \n",
    "                    #########comment breakpoint\n",
    "                    comments=[]\n",
    "                    try:\n",
    "                        commLink1 = soupCont.select('.fb-comments.fb_iframe_widget > span > iframe')[0]['src']\n",
    "                        commLink=re.sub(r\"numposts=\\d{1,3}&\", \"numposts=100&\", commLink1)\n",
    "                        resComm = requests.get(commLink)\n",
    "                        resComm.encoding = \"utf-8\"\n",
    "                        soupComm = BeautifulSoup(resComm.text)      \n",
    "                        commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "                        for comm in commentBlock: \n",
    "                            dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "                            commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "                            commentTime=dt.group(4)\n",
    "                            commenter=comm.select('.profileName')[0].text\n",
    "                            commenterUrl=comm.select('.profileName')[0]['href']\n",
    "                            comment=comm.select('.postText')[0].text\n",
    "                            comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: comment\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########comment breakpoint\n",
    "\n",
    "                    #########category breakpoint\n",
    "                    category=block.select('em')[0].text\n",
    "                    if not category == cat.decode(\"utf-8\"):\n",
    "                        try:\n",
    "                            raise Exception\n",
    "                        except Exception as e:\n",
    "                            f=open(\"ETTodayException.log\",\"a\")\n",
    "                            ExList=[\n",
    "                                \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                                \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                                \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                                \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                                \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                                \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                                \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                                \"\\t -Exception Traceback:\", \n",
    "                                traceback.format_exc() + \"\\n\"\n",
    "                            ]\n",
    "                            f.writelines(ExList)\n",
    "                            f.close\n",
    "                    #########category breakpoint\n",
    "    \n",
    "                    try:\n",
    "                        L.append({'class':category,'title':title,'newsDate':newsDate,'newsTime':newsTime,'journalist':journalist,'content':content,'hit':hit,'url':aLink,'source':'ETToday'})\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    #################連資料庫用\n",
    "                    hit = None\n",
    "                    #print category,title,newsDate,newsTime,journalist,content,hit,aLink,commentDate,commentTime,commenter,comment\n",
    "                    try:\n",
    "                        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                        insert_news(conn,category,title,newsDate,newsTime,journalist,content[0],hit,aLink)\n",
    "                        #insert_comments(conn,commentDate,commentTime,commenter,commenterUrl,comment,aLink)\n",
    "                        insert_newsRaw(conn,aLink,res.text)\n",
    "                        close(conn)\n",
    "                    except:\n",
    "                        print \"nothing write in DB\"\n",
    "                    #################連資料庫用\n",
    "                    time.sleep(sleep_time)\n",
    "    \n",
    "    \n",
    "    #########write_in_csv breakpoint\n",
    "    try:\n",
    "        # pandas - content\n",
    "        df = pd.DataFrame(L,columns =['class','title','newsDate','newsTime','journalist','content','hit','url','source'])\n",
    "        # pandas - comment\n",
    "        df_comm = pd.DataFrame(comments,columns =['commentDate','commentTime','commenter','commenterUrl','comment','url','remark'])\n",
    "        \n",
    "        # comment into MySQL\n",
    "        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "        for c in comments:\n",
    "            insert_comments(conn,c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5])\n",
    "        close(conn)\n",
    "        \n",
    "        # write csv\n",
    "        if (str(year)+str(month))==(str(year2)+str(month2)):\n",
    "            filename_content=\"ETTdoay_content_%d%02d.csv\"%(year,month)\n",
    "        else:\n",
    "            filename_comment=\"ETTdoay_comment_%d%02d-%d%02d.csv\"%(year,month,year2,month2)\n",
    "        ## write content in csv\n",
    "        f=open(filename_content,\"w\")\n",
    "        df.to_csv(filename_content,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        ## write comment in csv\n",
    "        f=open(filename_comment,\"w\")\n",
    "        df_comm.to_csv(filename_comment,encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        f=open(\"ETTodayException.log\",\"a\")\n",
    "        ExList=[\n",
    "            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "            \"\\t -BreakPoint: write_in_csv\" + \"\\n\",\n",
    "            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "            \"\\t -Exception Traceback:\", \n",
    "            traceback.format_exc() + \"\\n\"\n",
    "        ]\n",
    "        f.writelines(ExList)\n",
    "        f.close\n",
    "#########write_in_csv breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run\n",
    "ETToday_month(2015,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##直接輸入從今天算起要抓幾天 ETToday(days,category=[\"政治\",\"財經\",\"國際\",\"大陸\"],sleep_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import re\n",
    "from datetime import date,datetime, timedelta \n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "import traceback\n",
    "\n",
    "\n",
    "#################連資料庫用\n",
    "def connect(dbname,password,host,user,port=3306):\n",
    "    import MySQLdb\n",
    "    # 承德電腦 host=\"10.120.30.1\"\n",
    "    # localhost host = '127.0.0.1'\n",
    "    db = MySQLdb.connect(host=host,user=\"root\",passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(%s,%s,%s,%s,%s,%s,%s,%s,%s)\",[category,title,newsDate,newsTime,journalist,content,hit,url,source])\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(%s,%s,%s,%s,%s,%s)\" ,[commentDate,commentTime,commenter,commenterUrl,comment,url])\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,url,newsRaw):\n",
    "    cur = db.cursor()\n",
    "    cur.execute(\"insert into newsRaw(url,newsRaw)values(%s,%s)\",[url,newsRaw])\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "#################連資料庫用\n",
    "    \n",
    "def ETToday(days=1,sleep_time=0,category=[\"政治\",\"財經\",\"國際\",\"大陸\"]):\n",
    "    \n",
    "    ds = []\n",
    "    for i in xrange(1,days+1):\n",
    "        ds.append(str(date.today()- timedelta(i)))\n",
    "    \n",
    "    for newsDate in ds:\n",
    "        url_dic = {\"政治\":\"http://www.ettoday.net/news/news-list-%s-1.htm\"%newsDate,\n",
    "                    \"財經\":\"http://www.ettoday.net/news/news-list-%s-17.htm\"%newsDate,\n",
    "                    \"國際\":\"http://www.ettoday.net/news/news-list-%s-2.htm\"%newsDate,\n",
    "                    \"大陸\":\"http://www.ettoday.net/news/news-list-%s-3.htm\"%newsDate,\n",
    "                    \"社會\":\"http://www.ettoday.net/news/news-list-%s-6.htm\"%newsDate,\n",
    "                    \"地方\":\"http://www.ettoday.net/news/news-list-%s-7.htm\"%newsDate,\n",
    "                    \"影劇\":\"http://www.ettoday.net/news/news-list-%s-9.htm\"%newsDate,\n",
    "                    \"3C\":\"http://www.ettoday.net/news/news-list-%s-20.htm\"%newsDate\n",
    "                   }\n",
    "        \n",
    "        url_categories = {}\n",
    "        for cat in category:\n",
    "            url_categories[cat]=url_dic[cat]\n",
    "\n",
    "        L = []\n",
    "        for cat in url_categories:\n",
    "            try:\n",
    "                res = requests.get(url_categories[cat])\n",
    "                res.encoding=\"utf-8\"\n",
    "                soup = BeautifulSoup(res.text)\n",
    "                page = re.search('\\((\\d+).\\)',soup.select(\".info\")[0].text).group(1)\n",
    "                pageCount = int(math.ceil(float(page)/30))\n",
    "                soups = [soup]\n",
    "            except:\n",
    "                print url_categories[cat]\n",
    "                raise \n",
    "            if pageCount >1:\n",
    "                for i in xrange(2,pageCount+1):\n",
    "                    curl = str(url_categories[cat]).split(\".htm\")[0] + \"-\" + str(i) + \".htm\"\n",
    "                    res = requests.get(curl)\n",
    "                    res.encoding=\"utf-8\"\n",
    "                    soups.append(BeautifulSoup(res.text))\n",
    "\n",
    "            for soup in soups:         \n",
    "                for block in soup.select(\"#all-news-list > h3\"):\n",
    "                    try:\n",
    "                        timeRegex=re.search(\"\\[(\\d\\d)\\/(\\d\\d) (\\d{1,2}\\:\\d{1,2})\\]\",block.select('span')[0].text)\n",
    "                        testDate=timeRegex.group(1)+'-'+timeRegex.group(2)\n",
    "                        if not testDate == re.search('\\d{4}-(\\d\\d-\\d\\d)',newsDate).group(1).decode('utf-8'):\n",
    "                            continue\n",
    "                        newsTime=timeRegex.group(3)\n",
    "                        title=block.select('a')[0].text\n",
    "                        aLink=block.select('a')[0]['href']\n",
    "                    except:\n",
    "                        print url_categories[cat]\n",
    "                        raise\n",
    "                    #########get page breakpoint\n",
    "                    driver = webdriver.Firefox()\n",
    "                    #driver = webdriver.Chrome()\n",
    "                    #driver = webdriver.PhantomJS()\n",
    "                    driver.get(aLink)\n",
    "                    try:\n",
    "                        WebDriverWait(driver, 10).until(\n",
    "                                EC.visibility_of_element_located((By.ID, \"fbComments\"))\n",
    "                            )\n",
    "                        html = driver.page_source\n",
    "                        cont = str(html.encode('utf-8'))\n",
    "                        soupCont = BeautifulSoup(cont)\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: get page\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    finally:\n",
    "                        driver.quit()\n",
    "                    #########get page breakpoint\n",
    "\n",
    "                    #########content breakpoint\n",
    "                    try:\n",
    "                        content=\"\"\n",
    "                        contentRaw = soupCont.select('.story > sectione > p')\n",
    "                        for p in contentRaw:\n",
    "                            content = content + p.text\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: content\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback:\", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########content breakpoint\n",
    "\n",
    "                    try:\n",
    "                        for i in xrange(0,len(content)):\n",
    "                            for con in content[i].select('img'):\n",
    "                                content[i].img.decompose()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    #########journist breakpoint\n",
    "                    try:\n",
    "                        try:\n",
    "                            journalist=re.search('<p>([^圖].*?)／.*?報導<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            journalist=re.search('>文／(.*?)<',cont).group(1)\n",
    "                        except:\n",
    "                            pass\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: journist\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########journist breakpoint\n",
    "                    \n",
    "                    #########comment breakpoint\n",
    "                    comments=[]\n",
    "                    try:\n",
    "                        commLink1 = soupCont.select('.fb-comments.fb_iframe_widget > span > iframe')[0]['src']\n",
    "                        commLink=re.sub(r\"numposts=\\d{1,3}&\", \"numposts=100&\", commLink1)\n",
    "                        resComm = requests.get(commLink)\n",
    "                        resComm.encoding = \"utf-8\"\n",
    "                        soupComm = BeautifulSoup(resComm.text)      \n",
    "                        commentBlock=soupComm.select('.postContainer.fsl.fwb.fcb')\n",
    "                        for comm in commentBlock: \n",
    "                            dt=re.search(\"(\\d\\d\\d\\d).(\\d{1,2}).(\\d{1,2}). (\\d{1,2}\\:\\d{1,2})\",comm.select('abbr')[0]['title'])\n",
    "                            commentDate=\"%s-%02d-%02d\"%(dt.group(1),int(dt.group(2)),int(dt.group(3)))\n",
    "                            commentTime=dt.group(4)\n",
    "                            commenter=comm.select('.profileName')[0].text\n",
    "                            commenterUrl=comm.select('.profileName')[0]['href']\n",
    "                            comment=comm.select('.postText')[0].text\n",
    "                            comments.append({'commentDate':commentDate,'commentTime':commentTime,'commenter':commenter,'commenterUrl':commenterUrl,'comment':comment,'url':aLink,'remark':None})\n",
    "                    except Exception as e:\n",
    "                        f=open(\"ETTodayException.log\",\"a\")\n",
    "                        ExList=[\n",
    "                            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                            \"\\t -BreakPoint: comment\" + \"\\n\",\n",
    "                            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                            \"\\t -Exception Traceback: \", \n",
    "                            traceback.format_exc() + \"\\n\"\n",
    "                        ]\n",
    "                        f.writelines(ExList)\n",
    "                        f.close\n",
    "                    #########comment breakpoint\n",
    "\n",
    "                    #########category breakpoint\n",
    "                    category=block.select('em')[0].text\n",
    "                    if not category == cat.decode(\"utf-8\"):\n",
    "                        try:\n",
    "                            raise Exception\n",
    "                        except Exception as e:\n",
    "                            f=open(\"ETTodayException.log\",\"a\")\n",
    "                            ExList=[\n",
    "                                \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "                                \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "                                \"\\t -News Category: \" + cat + \"\\n\",\n",
    "                                \"\\t -News url: \" + aLink + \"\\n\",\n",
    "                                \"\\t -BreakPoint: category\" + \"\\n\",\n",
    "                                \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "                                \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "                                \"\\t -Exception Traceback:\", \n",
    "                                traceback.format_exc() + \"\\n\"\n",
    "                            ]\n",
    "                            f.writelines(ExList)\n",
    "                            f.close\n",
    "                    #########category breakpoint\n",
    "    \n",
    "                    try:\n",
    "                        L.append({'class':category,'title':title,'newsDate':newsDate,'newsTime':newsTime,'journalist':journalist,'content':content,'hit':hit,'url':aLink,'source':'ETToday'})\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    #################連資料庫用\n",
    "                    hit = None\n",
    "                    #print category,title,newsDate,newsTime,journalist,content,hit,aLink,commentDate,commentTime,commenter,comment\n",
    "                    try:\n",
    "                        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "                        insert_news(conn,category,title,newsDate,newsTime,journalist,content[0],hit,aLink)\n",
    "                        #insert_comments(conn,commentDate,commentTime,commenter,commenterUrl,comment,aLink)\n",
    "                        insert_newsRaw(conn,aLink,res.text)\n",
    "                        close(conn)\n",
    "                    except:\n",
    "                        print \"nothing write in DB\"\n",
    "                    #################連資料庫用\n",
    "                    time.sleep(sleep_time)\n",
    "    \n",
    "    \n",
    "    #########write_in_csv breakpoint\n",
    "    try:\n",
    "        # pandas - content\n",
    "        df = pd.DataFrame(L,columns =['class','title','newsDate','newsTime','journalist','content','hit','url','source'])\n",
    "        # pandas - comment\n",
    "        df_comm = pd.DataFrame(comments,columns =['commentDate','commentTime','commenter','commenterUrl','comment','url','remark'])\n",
    "        \n",
    "        # comment into MySQL\n",
    "        conn=connect(\"practice\",\"oblivn0374\",\"localhost\",\"root\")\n",
    "        for c in comments:\n",
    "            insert_comments(conn,c.values()[3],c.values()[6],c.values()[4],c.values()[1],c.values()[0],c.values()[5])\n",
    "        close(conn)\n",
    "        \n",
    "        # write content in csv\n",
    "        f=open(\"ETToday_content.csv\",\"w\")\n",
    "        df.to_csv(\"ETToday_content.csv\",encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        # write comment in csv\n",
    "        f=open(\"ETToday_comment.csv\",\"w\")\n",
    "        df_comm.to_csv(\"ETToday_comment.csv\",encoding=\"utf-8\")\n",
    "        f.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        f=open(\"ETTodayException.log\",\"a\")\n",
    "        ExList=[\n",
    "            \"Log at: \" + str(datetime.today()) + \"\\n\",\n",
    "            \"\\t -News Date: \" + newsDate + \"\\n\",\n",
    "            \"\\t -News Category: \" + cat + \"\\n\",\n",
    "            \"\\t -News url: \" + aLink + \"\\n\",\n",
    "            \"\\t -BreakPoint: write_in_csv\" + \"\\n\",\n",
    "            \"\\t -Exception Type: \" + str(e.__class__) + \"\\n\",\n",
    "            \"\\t -Exception Message: \" + e.message + \"\\n\",\n",
    "            \"\\t -Exception Traceback:\", \n",
    "            traceback.format_exc() + \"\\n\"\n",
    "        ]\n",
    "        f.writelines(ExList)\n",
    "        f.close\n",
    "#########write_in_csv breakpoint\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run\n",
    "ETToday(category=[\"政治\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://www.facebook.com/yijuamy.chen\"\n",
    "headers={\n",
    "':host':'www.facebook.com',\n",
    "':method':'GET',\n",
    "':path':'/yijuamy.chen',\n",
    "':scheme':'https',\n",
    "':version':'HTTP/1.1',\n",
    "'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "'accept-encoding':'gzip, deflate, sdch',\n",
    "'accept-language':'en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4',\n",
    "'cache-control':'max-age=0',\n",
    "'cookie':'datr=QBNeUwqI4S51V5AzGEoeCA1r; _ga=GA1.2.1275457108.1428803544; lu=TgMfpfq2tjUWZNCGMvAtPqgg; c_user=100000310235880; fr=0R1TtmugtGGZqdare.AWXzmmSln6UThlEI7X7DWth-8LI.BT6iv-.MD.FV-.0.AWXKXYOq; xs=46%3AcvZCripsh73rfw%3A2%3A1434196224%3A14635; csm=2; s=Aa5VbbutJxLdjkjE.BVfBkA; act=1434791149057%2F13; p=-2; presence=EM434791329EuserFA21B00310235880A2EstateFDsb2F0Et2F_5b_5dElm2FnullEuct2F1434788575BEtrFA2loadA2EtwF2521827791EatF1434791328792G434791159662CEchFDp_5f1B00310235880F0CC; wd=1239x259',\n",
    "'referer':'https://www.facebook.com/plugins/comments.php?api_key=146858218737386&channel_url=http%3A%2F%2Fstatic.ak.facebook.com%2Fconnect%2Fxd_arbiter%2F1ldYU13brY_.js%3Fversion%3D41%23cb%3Df3be262b0c%26domain%3Dwww.ettoday.net%26origin%3Dhttp%253A%252F%252Fwww.ettoday.net%252Ffc8173f04%26relation%3Dparent.parent&colorscheme=light&href=http%3A%2F%2Fwww.ettoday.net%2Fnews%2F20150612%2F520021.htm&locale=zh_TW&numposts=10&sdk=joey&skin=light&version=v2.0&width=620',\n",
    "'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
