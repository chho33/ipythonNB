{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def connect(dbname,password,host=\"localhost\",user=\"root\",port=3306):\n",
    "    import MySQLdb as mc \n",
    "    db = mc.connect(host=host,user=user,passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    data = (category,title,newsDate,newsTime,journalist,content,hit,url,source)\n",
    "    cur.execute('''insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\")''',data)\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    x = (commentDate,commentTime,commenter,commenterUrl,comment,url)\n",
    "    cur.execute('''insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\")''' ,x)\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,category,url,newsRaw,source):\n",
    "    cur = db.cursor()\n",
    "    t = (category,url,newsRaw,source)\n",
    "    cur.execute('''insert into newsRaw(`class`,url,newsRaw,source)values(\"%s\",\"%s\",\"%s\",\"%s\")''',t)\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import traceback\n",
    "import csv\n",
    "loginurl=\"http://udndata.com/ndapp/member/MbFixLogin?708869834\"\n",
    "headers={\n",
    "'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "'Accept-Encoding':'gzip, deflate, sdch',\n",
    "'Accept-Language':'en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4',\n",
    "'Connection':'keep-alive',\n",
    "'Host':'udndata.com',\n",
    "'Referer':'http://udndata.com/library/',\n",
    "'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "with open('xae.csv', 'rb') as csvfile:\n",
    "\trows = csv.reader(csvfile, delimiter='\\n', quotechar='\\t')\n",
    "\tfor r in rows:\n",
    "\t\ttry:\n",
    "            print \"start downloading\"\n",
    "\t\t\tf=open(\"ecoerror.txt\",\"a\")\n",
    "\t\t\tfc=open(\"collect.csv\",\"a\")\n",
    "            conn=connect(dbname=\"ecodaily3\",password=\"ho\",host=\"192.168.196.159\",user=\"ho\",port=3306)\n",
    "\t\t\trow=r[0].split(\"\\t\")[1]\n",
    "\t\t\tcategory=r[0].split(\"\\t\")[0]\n",
    "\t\t\t#print category, row\n",
    "\t\t\trs = requests.session()\n",
    "\t\t\trs.get(loginurl,headers=headers)\n",
    "\t\t\tres=rs.get(row).text\n",
    "\t\t\ttry :\n",
    "\t\t\t\tinsert_newsRaw(conn,category,row,res,\"Economoic Daily\")\n",
    "\t\t\t\tfc.write(category+\"\\t\"+row+\"\\n\")\n",
    "                print \"complete downloading :\", category,row,datetime.now()\n",
    "\t\t\texcept:\n",
    "                print \"failure: \", category,row,datetime.now()\n",
    "                print traceback.format_exc()\n",
    "\t\t\t\tf.write('error: '+row+\"\\n\")\n",
    "\t\t\t\tf.write( traceback.format_exc())\n",
    "            finally:\n",
    "                close(conn)\n",
    "                close(f)\n",
    "                close(fc)\n",
    "\t\texcept:\n",
    "            print \"failure: dont write\"\n",
    "            print traceback.format_exc()\n",
    "\t\t\tf.write('error: '+row+\"\\n\")\n",
    "\t\t\tf.write( traceback.format_exc())\n",
    "\t\t\ttime.sleep(5)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## grequests version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def connect(dbname,password,host=\"localhost\",user=\"root\",port=3306):\n",
    "    import MySQLdb as mc \n",
    "    db = mc.connect(host=host,user=user,passwd=password,db=dbname,charset=\"utf8\")\n",
    "    return db\n",
    "def insert_news(db,category=None,title=None,newsDate=None,newsTime=None,journalist=None,content=None,hit=None,url=None,source=\"ETToday\"):\n",
    "    cur = db.cursor()\n",
    "    data = (category,title,newsDate,newsTime,journalist,content,hit,url,source)\n",
    "    cur.execute('''insert into news(class,title,newsDate,newsTime,journalist,content,hit,url,source) values(\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\")''',data)\n",
    "    db.commit()\n",
    "def insert_comments(db,commentDate,commentTime,commenter,commenterUrl,comment,url,remark=None):\n",
    "    cur = db.cursor()\n",
    "    x = (commentDate,commentTime,commenter,commenterUrl,comment,url)\n",
    "    cur.execute('''insert into comments(commentDate,commentTime,commenter,commenterUrl,comment,url)values(\"%s\",\"%s\",\"%s\",\"%s\",\"%s\",\"%s\")''' ,x)\n",
    "    db.commit()\n",
    "def insert_newsRaw(db,category,url,newsRaw,source):\n",
    "    cur = db.cursor()\n",
    "    t = (category,url,newsRaw,source)\n",
    "    cur.execute('''insert into newsRaw(`class`,url,newsRaw,source)values(\"%s\",\"%s\",\"%s\",\"%s\")''',t)\n",
    "    db.commit()\n",
    "def close(db):\n",
    "    db.close()\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import traceback\n",
    "import csv\n",
    "import math\n",
    "import grequests\n",
    "from datetime import datetime\n",
    "loginurl=\"http://udndata.com/ndapp/member/MbFixLogin?708869834\"\n",
    "headers={\n",
    "'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "'Accept-Encoding':'gzip, deflate, sdch',\n",
    "'Accept-Language':'en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4',\n",
    "'Connection':'keep-alive',\n",
    "'Host':'udndata.com',\n",
    "'Referer':'http://udndata.com/library/',\n",
    "'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "b=time.clock()\n",
    "with open('t.csv', 'rb') as csvfile:    #改檔名\n",
    "    rows = csv.reader(csvfile, delimiter='\\n', quotechar='\\t')\n",
    "    all_url=[]\n",
    "    for rr in rows:\n",
    "        all_url.append(rr)\n",
    "\n",
    "\n",
    "with open('t.csv', 'rb') as csvfile:     #改檔名\n",
    "    groupurl=[]\n",
    "    groupcat=[]\n",
    "    count=0\n",
    "    newcount=0\n",
    "    headcount=len(all_url)%6\n",
    "    rows = csv.reader(csvfile, delimiter='\\n', quotechar='\\t')\n",
    "    i=0\n",
    "    for r in rows:\n",
    "        count+=1\n",
    "        newcount+=1\n",
    "        row=r[0].split(\"\\t\")[1]\n",
    "        category=r[0].split(\"\\t\")[0]\n",
    "        groupurl.append(row)\n",
    "        groupcat.append(category)\n",
    "        if count==headcount:\n",
    "            f=open(\"ecoerror.txt\",\"a\")    ##可改檔名\n",
    "            fc=open(\"collect.csv\",\"a\")    ##可改檔名\n",
    "            conn=connect(dbname=\"ecodaily3\",password=\"ho\",host=\"localhost\",user=\"ho\",port=3306)    #修改設定\n",
    "            try:\n",
    "                rs = requests.session()\n",
    "                rs.get(loginurl,headers=headers)\n",
    "                grs = (grequests.get(u,session=rs) for u in groupurl)\n",
    "                for response in grequests.map(grs):\n",
    "                    soup = BeautifulSoup(response.text)\n",
    "                    res=soup.prettify('utf-8')\n",
    "                    try :\n",
    "                        print \"start downloading...\"\n",
    "                        insert_newsRaw(conn,category,row,res,\"Economoic Daily\")\n",
    "                        fc.write(category+\"\\t\"+row+\"\\n\")\n",
    "                        print \"complete inserting :\", category,row,datetime.now(),\"\\n\"\n",
    "                    except:\n",
    "                        print \"failure to insert: \", category,row,datetime.now(),\"\\n\"\n",
    "                        f.write('error: '+row+\"\\n\")\n",
    "                        f.write( traceback.format_exc())\n",
    "            except:\n",
    "                print \"failure to download: \", category,row,datetime.now(),\"\\n\"\n",
    "                f.write('error: '+row+\"\\n\")\n",
    "                f.write( traceback.format_exc())\n",
    "                time.sleep(5)\n",
    "            finally:\n",
    "                groupurl=[]\n",
    "                groupcat=[]\n",
    "                newcount=0\n",
    "                close(conn)\n",
    "                close(f)\n",
    "                close(fc)\n",
    "                \n",
    "        if newcount%6==0:\n",
    "            if newcount==0:\n",
    "                pass\n",
    "            else:\n",
    "                f=open(\"ecoerror.txt\",\"a\")    ##可改檔名\n",
    "                fc=open(\"collect.csv\",\"a\")    ##可改檔名\n",
    "                conn=connect(dbname=\"ecodaily3\",password=\"ho\",host=\"localhost\",user=\"ho\",port=3306)    #修改設定\n",
    "                try:\n",
    "                    print \"start downloading...\"\n",
    "                    rs = requests.session()\n",
    "                    rs.get(loginurl,headers=headers)\n",
    "                    grs = (grequests.get(u,session=rs) for u in groupurl)\n",
    "                    for response in grequests.map(grs):\n",
    "                        soup = BeautifulSoup(response.text)\n",
    "                        res=soup.prettify('utf-8')\n",
    "                        try :\n",
    "                            insert_newsRaw(conn,category,row,res,\"Economoic Daily\")\n",
    "                            fc.write(category+\"\\t\"+row+\"\\n\")\n",
    "                            print \"complete inserting :\", category,row,datetime.now(),\"\\n\"\n",
    "                        except:\n",
    "                            print \"failure to insert: \", category,row,datetime.now(),\"\\n\"\n",
    "                            f.write('error: '+row+\"\\n\")\n",
    "                            f.write( traceback.format_exc())\n",
    "                except:\n",
    "                    print \"failure to download: \", category,row,datetime.now(),\"\\n\"\n",
    "                    f.write('error: '+row+\"\\n\")\n",
    "                    f.write( traceback.format_exc())\n",
    "                    time.sleep(5)\n",
    "                finally:\n",
    "                    groupurl=[]\n",
    "                    groupcat=[]\n",
    "                    newcount=0\n",
    "                    close(conn)\n",
    "                    close(f)\n",
    "                    close(fc)\n",
    "\n",
    "print time.clock()-b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
